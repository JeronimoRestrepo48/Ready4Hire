# ğŸ¯ Ready4Hire v2.2 - Sistema Completo de ProducciÃ³n

## âœ… Estado Actual: LISTO PARA PRODUCCIÃ“N

---

## ğŸ“¦ Lo que se ha creado

### 1. Scripts de ProducciÃ³n (6 scripts)

| Script | PropÃ³sito | Estado |
|--------|-----------|--------|
| `generate_demo_data.py` | Genera 200 evaluaciones sintÃ©ticas | âœ… TESTEADO |
| `convert_audit_log.py` | Convierte audit_log a training data | âœ… TESTEADO |
| `create_training_dataset.py` | Crea dataset en formato Alpaca | âœ… TESTEADO |
| `finetune_model.py` | Fine-tuning con Unsloth | âœ… LISTO |
| `import_to_ollama.py` | Importa modelo a Ollama | âœ… LISTO |
| `test_finetuned_model.py` | Testing completo del sistema | âœ… LISTO |

### 2. Scripts de AutomatizaciÃ³n

| Script | PropÃ³sito | Estado |
|--------|-----------|--------|
| `run_pipeline.py` | Pipeline completo interactivo | âœ… LISTO |
| `quickstart.sh` | Quick start bash script | âœ… LISTO |

### 3. DocumentaciÃ³n

| Archivo | Contenido |
|---------|-----------|
| `scripts/README.md` | DocumentaciÃ³n completa de scripts |
| `requirements.txt` | Dependencias del proyecto |

---

## ğŸš€ CÃ³mo Ejecutar el Sistema Completo

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)

```bash
cd /home/jeronimorestrepoangel/Documentos/Integracion/Ready4Hire
python3 scripts/run_pipeline.py
```

Este script ejecuta todo el flujo:
1. âœ… Genera 200 evaluaciones demo
2. âœ… Convierte a formato training data
3. âœ… Crea dataset Alpaca (train + validation)
4. âš ï¸ Fine-tuning (opcional, requiere GPU)
5. âš ï¸ Importa modelo a Ollama
6. âš ï¸ Testing completo

**Tiempo**: 5-10 minutos (sin fine-tuning)

---

### OpciÃ³n 2: Paso a Paso (Control Total)

#### Paso 1: Generar Datos Demo
```bash
python3 scripts/generate_demo_data.py --num-samples 200
```

**Output**: `logs/audit_log.jsonl` (200 evaluaciones)

---

#### Paso 2: Convertir a Training Data
```bash
python3 scripts/convert_audit_log.py
```

**Output**: `data/training/evaluations.jsonl` (formato TrainingExample)

---

#### Paso 3: Crear Dataset
```bash
python3 scripts/create_training_dataset.py --min-score 7.0
```

**Output**: 
- `app/datasets/ready4hire_dataset_train.jsonl`
- `app/datasets/ready4hire_dataset_val.jsonl`

---

#### Paso 4: Fine-Tuning (Requiere GPU)

**Pre-requisitos**:
- GPU con CUDA
- 8GB+ VRAM
- 30-120 minutos

```bash
# Instalar Unsloth
pip install unsloth

# Fine-tuning
python3 scripts/finetune_model.py \
    --epochs 3 \
    --batch-size 2 \
    --learning-rate 2e-4
```

**Output**: 
- `models/ready4hire-finetuned/` (modelo completo)
- `models/ready4hire-finetuned/*.gguf` (formato GGUF)

---

#### Paso 5: Importar a Ollama
```bash
python3 scripts/import_to_ollama.py --model-name ready4hire:latest
```

**Output**: Modelo `ready4hire:latest` disponible en Ollama

**Verificar**:
```bash
ollama list
ollama run ready4hire:latest
```

---

#### Paso 6: Testing
```bash
# Test bÃ¡sico
python3 scripts/test_finetuned_model.py

# Con comparaciÃ³n vs modelo base
python3 scripts/test_finetuned_model.py --compare --base-model llama3.2:3b
```

**Output**: 
- Reporte de accuracy
- ComparaciÃ³n de scores
- `tests/results/test_results.json`

---

## ğŸ“Š Flujo de Datos

```
audit_log.jsonl (demo data)
    â†“
evaluations.jsonl (training data)
    â†“
dataset_train.jsonl + dataset_val.jsonl (Alpaca format)
    â†“
Fine-Tuning (Unsloth)
    â†“
ready4hire-finetuned/ (modelo entrenado)
    â†“
ready4hire.gguf (formato GGUF)
    â†“
Ollama (ready4hire:latest)
    â†“
Testing + Deployment
```

---

## ğŸ¯ Siguientes Pasos

### Sin Fine-Tuning (Desarrollo/Testing)

```bash
# 1. Generar datos demo
python3 scripts/generate_demo_data.py --num-samples 200

# 2. Convertir a training data
python3 scripts/convert_audit_log.py

# 3. Crear dataset
python3 scripts/create_training_dataset.py

# 4. Iniciar app con modelo base
python3 -m uvicorn app.main:app --reload

# 5. Abrir navegador
# http://localhost:8000
```

**Tiempo total**: ~5 minutos

---

### Con Fine-Tuning (ProducciÃ³n)

```bash
# Ejecutar pipeline completo
python3 scripts/run_pipeline.py

# Responder 'y' cuando pregunte por fine-tuning

# DespuÃ©s de completar:
python3 -m uvicorn app.main:app --reload
```

**Tiempo total**: 45-150 minutos (dependiendo de GPU)

---

## ğŸ› Troubleshooting

### Error: "No training examples found"
```bash
# Ejecutar en orden:
python3 scripts/generate_demo_data.py --num-samples 200
python3 scripts/convert_audit_log.py
python3 scripts/create_training_dataset.py
```

### Error: "unsloth not found"
```bash
pip install unsloth
# o
pip install unsloth @ git+https://github.com/unslothai/unsloth.git
```

### Error: "CUDA out of memory"
```bash
# Reducir batch size
python3 scripts/finetune_model.py --batch-size 1
```

### Error: "Ollama connection refused"
```bash
# Iniciar Ollama
ollama serve &
sleep 3
ollama list
```

---

## ğŸ“ˆ MÃ©tricas de Ã‰xito

Un fine-tuning exitoso deberÃ­a mostrar:

âœ… **Accuracy**: >80% en tests  
âœ… **SeparaciÃ³n**: >3.0 puntos entre buenas y malas respuestas  
âœ… **Mejora vs Base**: +10% o mÃ¡s en accuracy  

Ejemplo de output exitoso:
```
COMPARACIÃ“N: BASE vs FINE-TUNED
================================
Accuracy:
  Base model: 60.0%
  Fine-tuned: 85.0%
  Mejora: +25.0%

SeparaciÃ³n (good - bad):
  Base model: 2.3
  Fine-tuned: 4.8
  Mejora: +2.5

âœ… FINE-TUNING EXITOSO: El modelo mejorÃ³
```

---

## ğŸ”§ ConfiguraciÃ³n del Sistema

### Modelo Base vs Fine-Tuned

Editar `.env` o variables de entorno:

```bash
# Usar modelo base
MODEL_NAME=llama3.2:3b

# Usar modelo fine-tuned
MODEL_NAME=ready4hire:latest
```

---

## ğŸ“ Logs y Outputs

| Archivo | DescripciÃ³n |
|---------|-------------|
| `logs/audit_log.jsonl` | Evaluaciones recopiladas |
| `data/training/evaluations.jsonl` | Training data (TrainingExample) |
| `app/datasets/train.jsonl` | Dataset de entrenamiento (Alpaca) |
| `app/datasets/validation.jsonl` | Dataset de validaciÃ³n (Alpaca) |
| `models/ready4hire-finetuned/` | Modelo fine-tuned completo |
| `tests/results/test_results.json` | Resultados de testing |

---

## ğŸ“ DocumentaciÃ³n Adicional

- **Scripts**: `scripts/README.md`
- **Arquitectura**: `README.md` (raÃ­z del proyecto)
- **API**: FastAPI auto-docs en `/docs` cuando la app estÃ¡ corriendo

---

## âœ… Checklist de Deployment

### Pre-Deployment
- [ ] Datos demo generados (200+ evaluaciones)
- [ ] Dataset creado (train + validation)
- [ ] Fine-tuning completado (opcional pero recomendado)
- [ ] Modelo importado a Ollama
- [ ] Tests ejecutados (>80% accuracy)

### Deployment
- [ ] `.env` configurado con `MODEL_NAME=ready4hire:latest`
- [ ] Ollama corriendo (`ollama serve`)
- [ ] Modelo verificado (`ollama list`)
- [ ] App iniciada (`uvicorn app.main:app`)
- [ ] Tests de integraciÃ³n pasando

### Post-Deployment
- [ ] Monitorear logs
- [ ] Recopilar evaluaciones reales
- [ ] Re-entrenar con datos de producciÃ³n (>500 evaluaciones)
- [ ] A/B testing (base vs fine-tuned)

---

## ğŸ‰ Â¡Sistema Listo!

El sistema estÃ¡ completamente funcional y listo para:
- âœ… Desarrollo y testing
- âœ… Fine-tuning (con GPU)
- âœ… Deployment a producciÃ³n
- âœ… RecolecciÃ³n de datos reales
- âœ… Re-entrenamiento continuo

---

**Ready4Hire v2.2**  
Sistema de IA para entrevistas tÃ©cnicas con fine-tuning LLM  
Â© 2025
