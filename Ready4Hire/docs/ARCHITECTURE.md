# ğŸ›ï¸ Arquitectura Ready4Hire - DocumentaciÃ³n TÃ©cnica

## ğŸ“‹ Tabla de Contenidos

1. [VisiÃ³n General](#visiÃ³n-general)
2. [Decisiones de Arquitectura](#decisiones-de-arquitectura)
3. [Domain Layer](#domain-layer---lÃ³gica-de-negocio)
4. [Application Layer](#application-layer---casos-de-uso)
5. [Infrastructure Layer](#infrastructure-layer---implementaciones)
6. [Flujos de Datos](#flujos-de-datos)
7. [Patrones de DiseÃ±o](#patrones-de-diseÃ±o-implementados)
8. [Escalabilidad y Performance](#escalabilidad-y-performance)
9. [Seguridad](#seguridad)
10. [MigraciÃ³n y EvoluciÃ³n](#migraciÃ³n-y-evoluciÃ³n)

---

## VisiÃ³n General

Ready4Hire implementa una **arquitectura limpia basada en Domain-Driven Design (DDD)** con separaciÃ³n estricta de responsabilidades en 3 capas principales. Esta arquitectura reemplaza el sistema monolÃ­tico anterior (1422 lÃ­neas en un solo archivo) por una estructura modular, testable y mantenible.

### Principios ArquitectÃ³nicos

1. **Dependency Inversion**: Las capas externas dependen de las internas, nunca al revÃ©s
2. **Single Responsibility**: Cada componente tiene una Ãºnica razÃ³n para cambiar
3. **Open/Closed**: Abierto para extensiÃ³n, cerrado para modificaciÃ³n
4. **Testability First**: Todas las capas son testeables de forma aislada
5. **Explicit is Better**: Contratos explÃ­citos (interfaces) sobre implementaciones concretas

---

## Decisiones de Arquitectura

### ADR-001: Domain-Driven Design

**Contexto**: Sistema monolÃ­tico de 1422 lÃ­neas difÃ­cil de mantener, testear y escalar.

**DecisiÃ³n**: Adoptar DDD con separaciÃ³n en 3 capas (Domain, Application, Infrastructure).

**Consecuencias**:
- âœ… **Positivas**: 
  - LÃ³gica de negocio aislada y testeable
  - Facilita agregar nuevas features sin romper existentes
  - Permite cambiar implementaciones (BD, ML) sin tocar dominio
- âš ï¸ **Negativas**:
  - Mayor cantidad de archivos (50+ vs 8)
  - Curva de aprendizaje para desarrolladores nuevos
  - MÃ¡s boilerplate inicial

**Alternativas consideradas**:
- MVC tradicional: Rechazado (mezcla lÃ³gica de negocio con presentaciÃ³n)
- Microservicios: Rechazado (overhead para tamaÃ±o actual del proyecto)

---

### ADR-002: ML Real vs Stubs

**Contexto**: Sistema anterior usaba "ML fake" (stubs con lÃ³gica hardcodeada).

**DecisiÃ³n**: Implementar modelos ML reales (HuggingFace Transformers, PyTorch).

**Consecuencias**:
- âœ… **Positivas**:
  - DetecciÃ³n real de emociones con 85%+ precisiÃ³n
  - Soporte multilingÃ¼e (ES + EN)
  - Ajuste dinÃ¡mico de dificultad basado en features reales
- âš ï¸ **Negativas**:
  - Mayor uso de CPU/RAM (modelos ~500MB)
  - Latencia adicional en primera inferencia (~2-3s, luego <200ms)
  - Requiere gestiÃ³n de cache de modelos

**MitigaciÃ³n**:
- Lazy loading de modelos (solo se cargan cuando se usan)
- Cache de modelos en memoria
- Fallback heurÃ­stico si ML falla

---

### ADR-003: LLM para EvaluaciÃ³n

**Contexto**: Necesidad de evaluar respuestas de forma inteligente y contextual.

**DecisiÃ³n**: Usar LLMs (OpenAI GPT-4 / Anthropic Claude) con fallback heurÃ­stico.

**Consecuencias**:
- âœ… **Positivas**:
  - EvaluaciÃ³n profunda y contextualizada
  - Feedback personalizado de alta calidad
  - Captura conceptos que heurÃ­sticas no detectan
- âš ï¸ **Negativas**:
  - Dependencia de APIs externas (costo, latencia, disponibilidad)
  - Costo variable segÃºn uso (~$0.03-0.06 por respuesta con GPT-4)

**MitigaciÃ³n**:
- Fallback heurÃ­stico automÃ¡tico (basado en longitud, keywords)
- Rate limiting y retry logic
- Cache de evaluaciones frecuentes (futuro)

---

## Domain Layer - LÃ³gica de Negocio

### Entities (Entidades)

#### Interview (Aggregate Root)
```python
class Interview:
    """
    RaÃ­z del agregado Interview.
    Orquesta toda la lÃ³gica de una entrevista.
    """
    def __init__(
        self,
        id: str,
        user_id: str,
        role: str,
        category: str,
        current_difficulty: SkillLevel,
        max_questions: int = 10
    ):
        self.id = id
        self.user_id = user_id
        self.role = role
        self.category = category
        self.status = InterviewStatus.CREATED
        self.current_difficulty = current_difficulty
        self.max_questions = max_questions
        self.current_question_index = 0
        self.questions: List[str] = []  # IDs de preguntas
        self.answers: List[Answer] = []
        # Timestamps
        self.created_at = datetime.utcnow()
        self.started_at: Optional[datetime] = None
        self.completed_at: Optional[datetime] = None
        self.paused_at: Optional[datetime] = None
    
    # MÃ©todos de negocio
    def start(self) -> None:
        """Iniciar entrevista con validaciones."""
        if self.status != InterviewStatus.CREATED:
            raise ValueError("Interview already started")
        self.status = InterviewStatus.ACTIVE
        self.started_at = datetime.utcnow()
    
    def add_question(self, question_id: str) -> None:
        """Agregar pregunta con validaciones."""
        if self.status not in [InterviewStatus.ACTIVE, InterviewStatus.PAUSED]:
            raise ValueError("Cannot add question to inactive interview")
        if len(self.questions) >= self.max_questions:
            raise ValueError("Max questions reached")
        self.questions.append(question_id)
    
    def add_answer(self, answer: Answer) -> None:
        """Agregar respuesta y actualizar estado."""
        if self.status != InterviewStatus.ACTIVE:
            raise ValueError("Interview not active")
        self.answers.append(answer)
        self.current_question_index += 1
    
    def get_score_average(self) -> float:
        """Calcular promedio de puntuaciones."""
        if not self.answers:
            return 0.0
        scores = [a.score.value for a in self.answers if a.score]
        return sum(scores) / len(scores) if scores else 0.0
    
    def get_accuracy(self) -> float:
        """Calcular porcentaje de respuestas correctas (score >= 6)."""
        if not self.answers:
            return 0.0
        correct = sum(1 for a in self.answers if a.score and a.score.value >= 6.0)
        return (correct / len(self.answers)) * 100
    
    def needs_difficulty_adjustment(self) -> bool:
        """Determinar si se debe ajustar dificultad."""
        if len(self.answers) < 3:
            return False
        recent_scores = [a.score.value for a in self.answers[-3:] if a.score]
        avg_recent = sum(recent_scores) / len(recent_scores) if recent_scores else 0
        # Subir si Ãºltimas 3 respuestas promedio >= 7.5
        # Bajar si Ãºltimas 3 respuestas promedio < 5.0
        return avg_recent >= 7.5 or avg_recent < 5.0
```

**Reglas de negocio en Interview:**
1. Solo se puede iniciar una entrevista CREATED
2. Solo se pueden agregar preguntas si estÃ¡ ACTIVE o PAUSED
3. MÃ¡ximo `max_questions` preguntas por entrevista
4. Ajuste de dificultad basado en Ãºltimas 3 respuestas
5. Accuracy considera correctas las respuestas con score >= 6.0

#### Question
```python
@dataclass
class Question:
    """Entidad Question con metadata para evaluaciÃ³n."""
    id: str
    role: str
    category: str  # 'technical' | 'soft_skills'
    difficulty: SkillLevel
    question_text: str
    keywords: List[str]
    expected_concepts: List[str]
    metadata: Dict[str, Any] = field(default_factory=dict)
```

#### Answer
```python
@dataclass
class Answer:
    """Entidad Answer con evaluaciÃ³n completa."""
    id: str
    question_id: str
    answer_text: str
    score: Score
    emotion: Emotion
    time_taken_seconds: int
    hints_used: int = 0
    evaluation_details: Dict[str, Any] = field(default_factory=dict)
    feedback: str = ""
    created_at: datetime = field(default_factory=datetime.utcnow)
```

### Value Objects

#### Score
```python
class Score:
    """
    Value Object para puntuaciones (0-10).
    Inmutable, validado.
    """
    def __init__(self, value: float):
        if not 0 <= value <= 10:
            raise ValueError("Score must be between 0 and 10")
        self._value = round(value, 1)
    
    @property
    def value(self) -> float:
        return self._value
    
    def is_passing(self) -> bool:
        """Considera aprobado si score >= 6.0"""
        return self._value >= 6.0
    
    def quality_level(self) -> str:
        """Retorna nivel de calidad."""
        if self._value >= 9.0:
            return "excellent"
        elif self._value >= 7.0:
            return "good"
        elif self._value >= 5.0:
            return "acceptable"
        else:
            return "needs_improvement"
```

#### Emotion
```python
class Emotion(Enum):
    """Enum de emociones detectables."""
    JOY = "joy"
    SADNESS = "sadness"
    ANGER = "anger"
    FEAR = "fear"
    SURPRISE = "surprise"
    NEUTRAL = "neutral"
    
    def sentiment(self) -> str:
        """Clasifica en positivo/negativo/neutral."""
        if self in [Emotion.JOY, Emotion.SURPRISE]:
            return "positive"
        elif self in [Emotion.SADNESS, Emotion.ANGER, Emotion.FEAR]:
            return "negative"
        else:
            return "neutral"
```

#### SkillLevel
```python
class SkillLevel(Enum):
    """Niveles de habilidad con transiciones."""
    JUNIOR = "junior"
    MID = "mid"
    SENIOR = "senior"
    
    def can_increase_to(self, other: 'SkillLevel') -> bool:
        """Valida transiciÃ³n vÃ¡lida."""
        transitions = {
            SkillLevel.JUNIOR: [SkillLevel.MID],
            SkillLevel.MID: [SkillLevel.SENIOR],
            SkillLevel.SENIOR: []
        }
        return other in transitions[self]
    
    def to_numeric(self) -> int:
        """ConversiÃ³n a numÃ©rico para cÃ¡lculos."""
        return {
            SkillLevel.JUNIOR: 0,
            SkillLevel.MID: 1,
            SkillLevel.SENIOR: 2
        }[self]
```

### Repository Interfaces (Ports)

```python
from abc import ABC, abstractmethod

class InterviewRepository(ABC):
    """Interfaz para persistencia de Interview."""
    
    @abstractmethod
    async def save(self, interview: Interview) -> None:
        """Guardar o actualizar entrevista."""
        pass
    
    @abstractmethod
    async def find_by_id(self, interview_id: str) -> Optional[Interview]:
        """Buscar por ID."""
        pass
    
    @abstractmethod
    async def find_active_by_user(self, user_id: str) -> Optional[Interview]:
        """Buscar entrevista activa del usuario."""
        pass
    
    @abstractmethod
    async def find_all_by_user(self, user_id: str) -> List[Interview]:
        """Listar todas las entrevistas de un usuario."""
        pass
```

**Beneficios del Repository Pattern:**
- Domain no conoce detalles de persistencia (SQL, NoSQL, memoria)
- FÃ¡cil cambiar implementaciÃ³n (Memory â†’ PostgreSQL)
- Testeabilidad con mocks
- Queries de negocio encapsuladas

---

## Application Layer - Casos de Uso

### Use Cases

#### StartInterviewUseCase
```python
class StartInterviewUseCase:
    """
    Caso de uso: Iniciar nueva entrevista.
    Orquesta validaciones, creaciÃ³n de entidad y persistencia.
    """
    def __init__(
        self,
        interview_repo: InterviewRepository,
        question_repo: QuestionRepository,
        question_selector: QuestionSelectorService
    ):
        self.interview_repo = interview_repo
        self.question_repo = question_repo
        self.question_selector = question_selector
    
    async def execute(
        self,
        user_id: str,
        role: str,
        category: str,
        initial_difficulty: SkillLevel = SkillLevel.MID
    ) -> Dict[str, Any]:
        """
        Flujo:
        1. Validar que no haya entrevista activa
        2. Crear Interview entity
        3. Seleccionar primera pregunta
        4. Iniciar entrevista
        5. Persistir
        6. Retornar resultado
        """
        # 1. Validar
        existing = await self.interview_repo.find_active_by_user(user_id)
        if existing:
            raise ValueError("User already has active interview")
        
        # 2. Crear entidad
        interview = Interview(
            id=str(uuid.uuid4()),
            user_id=user_id,
            role=role,
            category=category,
            current_difficulty=initial_difficulty
        )
        
        # 3. Seleccionar primera pregunta
        first_question = await self.question_selector.select_initial_question(
            role=role,
            category=category,
            difficulty=initial_difficulty
        )
        
        # 4. Iniciar
        interview.start()
        interview.add_question(first_question.id)
        
        # 5. Persistir
        await self.interview_repo.save(interview)
        
        # 6. Retornar
        return {
            "interview_id": interview.id,
            "message": f"Â¡Bienvenido! Entrevista {category} para {role}.",
            "first_question": {
                "id": first_question.id,
                "text": first_question.question_text,
                "difficulty": first_question.difficulty.value
            }
        }
```

#### ProcessAnswerUseCase
```python
class ProcessAnswerUseCase:
    """
    Caso de uso: Procesar respuesta del candidato.
    Orquesta detecciÃ³n emociÃ³n, evaluaciÃ³n, feedback y siguiente pregunta.
    """
    def __init__(
        self,
        interview_repo: InterviewRepository,
        question_repo: QuestionRepository,
        emotion_detector: MultilingualEmotionDetector,
        evaluation_service: EvaluationService,
        feedback_service: FeedbackService,
        question_selector: QuestionSelectorService
    ):
        self.interview_repo = interview_repo
        self.question_repo = question_repo
        self.emotion_detector = emotion_detector
        self.evaluation_service = evaluation_service
        self.feedback_service = feedback_service
        self.question_selector = question_selector
    
    async def execute(
        self,
        interview_id: str,
        answer_text: str
    ) -> Dict[str, Any]:
        """
        Flujo:
        1. Recuperar entrevista y pregunta actual
        2. Detectar emociÃ³n
        3. Evaluar respuesta con LLM
        4. Generar feedback personalizado
        5. Crear Answer entity
        6. Seleccionar siguiente pregunta (si no terminÃ³)
        7. Persistir
        8. Retornar resultado
        """
        # 1. Recuperar
        interview = await self.interview_repo.find_by_id(interview_id)
        if not interview:
            raise ValueError("Interview not found")
        
        current_q_id = interview.questions[-1]
        question = await self.question_repo.find_by_id(current_q_id)
        
        # 2. Detectar emociÃ³n
        emotion_result = self.emotion_detector.detect(answer_text)
        emotion = emotion_result['emotion']
        
        # 3. Evaluar
        evaluation = await self.evaluation_service.evaluate_answer(
            question=question.question_text,
            answer=answer_text,
            expected_concepts=question.expected_concepts,
            keywords=question.keywords,
            category=question.category,
            difficulty=question.difficulty.value,
            role=question.role
        )
        
        # 4. Feedback
        feedback = await self.feedback_service.generate_feedback(
            question=question.question_text,
            answer=answer_text,
            evaluation=evaluation,
            emotion=emotion.value,
            role=interview.role,
            category=interview.category,
            performance_history=[a.to_dict() for a in interview.answers]
        )
        
        # 5. Crear Answer
        answer = Answer(
            id=str(uuid.uuid4()),
            question_id=question.id,
            answer_text=answer_text,
            score=Score(evaluation['score']),
            emotion=emotion,
            time_taken_seconds=0,  # TODO: trackear tiempo
            evaluation_details=evaluation,
            feedback=feedback
        )
        
        interview.add_answer(answer)
        
        # 6. Siguiente pregunta
        next_question = None
        if interview.current_question_index < interview.max_questions:
            next_question = await self.question_selector.select_next_question(
                interview=interview,
                previous_question_ids=interview.questions,
                last_answer_score=evaluation['score']
            )
            if next_question:
                interview.add_question(next_question.id)
        else:
            interview.complete()
        
        # 7. Persistir
        await self.interview_repo.save(interview)
        
        # 8. Retornar
        result = {
            "evaluation": evaluation,
            "emotion": {
                "detected": emotion.value,
                "confidence": emotion_result['confidence'],
                "language": emotion_result['language']
            },
            "feedback": feedback,
            "progress": {
                "current": interview.current_question_index,
                "total": interview.max_questions,
                "percentage": (interview.current_question_index / interview.max_questions) * 100
            }
        }
        
        if next_question:
            result["next_question"] = {
                "id": next_question.id,
                "text": next_question.question_text,
                "difficulty": next_question.difficulty.value
            }
        
        return result
```

### Services (Servicios de AplicaciÃ³n)

#### EvaluationService
**Responsabilidad**: Evaluar respuestas usando LLM con fallback heurÃ­stico.

**Algoritmo**:
1. Construir prompt estructurado con contexto
2. Llamar LLM (OpenAI/Anthropic)
3. Parsear respuesta JSON
4. Validar estructura y rangos
5. Si falla: usar evaluaciÃ³n heurÃ­stica (longitud, keywords)

**Input**: Question, Answer, ExpectedConcepts, Keywords
**Output**: 
```json
{
  "score": 7.5,
  "breakdown": {
    "completeness": 2.5,
    "technical_depth": 2.0,
    "clarity": 1.5,
    "key_concepts": 1.5
  },
  "justification": "...",
  "strengths": ["...", "..."],
  "improvements": ["...", "..."],
  "concepts_covered": ["...", "..."]
}
```

#### FeedbackService
**Responsabilidad**: Generar feedback personalizado considerando emociÃ³n.

**Estrategia**:
- Tono adaptado a emociÃ³n:
  - `joy/neutral`: Positivo y motivador
  - `sadness/fear`: EmpÃ¡tico y alentador
  - `anger`: Calmado y comprensivo
  - `surprise`: Entusiasta y guÃ­a

**Longitud**: 80-120 palabras (3-4 oraciones)

#### QuestionSelectorService
**Responsabilidad**: Seleccionar siguiente pregunta adaptÃ¡ndose al rendimiento.

**Estrategia de selecciÃ³n**:
1. **Ajuste de dificultad**:
   - Si score Ãºltima respuesta >= 7.5: Subir dificultad
   - Si score < 5.0: Bajar dificultad
   - Else: Mantener

2. **Diversidad semÃ¡ntica** (si embeddings disponibles):
   - Calcular distancia coseno con Ãºltimas 3 preguntas
   - Seleccionar la mÃ¡s diversa (mÃ¡xima distancia promedio)

3. **Fallback**:
   - SelecciÃ³n aleatoria de pool vÃ¡lido

---

## Infrastructure Layer - Implementaciones

### Persistence (Adaptadores)

#### MemoryInterviewRepository
```python
class MemoryInterviewRepository(InterviewRepository):
    """ImplementaciÃ³n en memoria (desarrollo, tests)."""
    def __init__(self):
        self._storage: Dict[str, Interview] = {}
        self._user_index: Dict[str, List[str]] = {}
    
    async def save(self, interview: Interview) -> None:
        self._storage[interview.id] = interview
        if interview.user_id not in self._user_index:
            self._user_index[interview.user_id] = []
        if interview.id not in self._user_index[interview.user_id]:
            self._user_index[interview.user_id].append(interview.id)
    
    async def find_by_id(self, interview_id: str) -> Optional[Interview]:
        return self._storage.get(interview_id)
    
    async def find_active_by_user(self, user_id: str) -> Optional[Interview]:
        interview_ids = self._user_index.get(user_id, [])
        for iid in interview_ids:
            interview = self._storage.get(iid)
            if interview and interview.status == InterviewStatus.ACTIVE:
                return interview
        return None
```

#### PostgresInterviewRepository (TODO)
```python
class PostgresInterviewRepository(InterviewRepository):
    """ImplementaciÃ³n con PostgreSQL (async)."""
    def __init__(self, pool: asyncpg.Pool):
        self.pool = pool
    
    async def save(self, interview: Interview) -> None:
        async with self.pool.acquire() as conn:
            # Serializar Interview a JSON
            data = interview.to_dict()
            await conn.execute("""
                INSERT INTO interviews (id, user_id, role, status, data, updated_at)
                VALUES ($1, $2, $3, $4, $5, NOW())
                ON CONFLICT (id) DO UPDATE SET
                    status = EXCLUDED.status,
                    data = EXCLUDED.data,
                    updated_at = NOW()
            """, interview.id, interview.user_id, interview.role, 
                interview.status.value, json.dumps(data))
```

### ML Models (Adaptadores)

#### MultilingualEmotionDetector
**TecnologÃ­a**: HuggingFace Transformers

**Modelos**:
- EspaÃ±ol: `finiteautomata/bertweet-base-emotion-analysis`
- InglÃ©s: `j-hartmann/emotion-english-distilroberta-base`

**Flujo**:
1. Detectar idioma con `langid`
2. Cargar modelo apropiado (lazy loading)
3. Ejecutar inferencia
4. Mapear labels a `Emotion` enum
5. Retornar resultado con confianza

**Performance**:
- Primera inferencia: ~2-3s (descarga modelo)
- Siguientes: <200ms (modelo en cache)
- TamaÃ±o modelos: ~500MB total

#### NeuralDifficultyAdjuster
**TecnologÃ­a**: PyTorch

**Arquitectura**:
```
Input Layer (12 features)
    â†“
Dense(64) + ReLU
    â†“
Dense(32) + ReLU
    â†“
Output Layer (3) â†’ Softmax
    â†“
[P(JUNIOR), P(MID), P(SENIOR)]
```

**Features extraÃ­das**:
1. avg_score: Promedio de puntuaciones
2. consistency: DesviaciÃ³n estÃ¡ndar de scores
3. avg_time: Tiempo promedio de respuesta
4. emotion_positive_ratio: % emociones positivas
5. emotion_negative_ratio: % emociones negativas
6. correct_ratio: % respuestas correctas (score >= 6)
7. accuracy: PrecisiÃ³n general
8. hints_used_avg: Promedio de pistas usadas
9. current_difficulty_num: Dificultad actual (0-2)
10. questions_answered: Cantidad respondidas
11. trend: Tendencia (Ãºltimas 3 respuestas)
12. time_variance: Varianza de tiempos

**Training**: TODO (actualmente usa heurÃ­stica hasta entrenar modelo)

---

## Flujos de Datos

### Flujo Completo: Responder Pregunta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. API Endpoint                                               â”‚
â”‚    POST /answer                                               â”‚
â”‚    Body: {user_id, answer_text}                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ProcessAnswerUseCase.execute()                            â”‚
â”‚    - Recuperar Interview del repositorio                      â”‚
â”‚    - Recuperar Question actual                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼            â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Emotion â”‚  â”‚Evaluation  â”‚  â”‚Feedbackâ”‚  â”‚Question  â”‚
â”‚Detectorâ”‚  â”‚Service     â”‚  â”‚Service â”‚  â”‚Selector  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚             â”‚            â”‚
    â”‚ detect()    â”‚ evaluate()  â”‚ generate() â”‚ select_next()
    â”‚             â”‚             â”‚            â”‚
    â–¼             â–¼             â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ML Modelâ”‚  â”‚OpenAI/     â”‚  â”‚OpenAI/ â”‚  â”‚Embeddingsâ”‚
â”‚(Trans- â”‚  â”‚Anthropic   â”‚  â”‚Anthrop â”‚  â”‚Manager   â”‚
â”‚formers)â”‚  â”‚API         â”‚  â”‚ic API  â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚             â”‚            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Crear Answer Entity                                        â”‚
â”‚    Answer(score, emotion, feedback, ...)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Actualizar Interview                                       â”‚
â”‚    interview.add_answer(answer)                               â”‚
â”‚    interview.add_question(next_question_id)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Persistir                                                  â”‚
â”‚    interview_repo.save(interview)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Retornar Resultado                                         â”‚
â”‚    {evaluation, emotion, feedback, next_question, progress}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos: DetecciÃ³n de EmociÃ³n

```
answer_text
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MultilingualEmotionDet  â”‚
â”‚ .detect(text)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ langid.classify(text)   â”‚
â”‚ â†’ 'es' | 'en'           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ES Modelâ”‚ â”‚EN Modelâ”‚
â”‚bertweetâ”‚ â”‚distil  â”‚
â”‚        â”‚ â”‚roberta â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = [             â”‚
â”‚   {label: 'joy',        â”‚
â”‚    score: 0.85},        â”‚
â”‚   {label: 'neutral',    â”‚
â”‚    score: 0.10},        â”‚
â”‚   ...                   â”‚
â”‚ ]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ best = max(results)     â”‚
â”‚ emotion = map_to_enum() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
{
  'emotion': Emotion.JOY,
  'confidence': 0.85,
  'all_emotions': [...],
  'language': 'es'
}
```

---

## Patrones de DiseÃ±o Implementados

### 1. Repository Pattern
**Uso**: Persistencia de Interviews y Questions
**Beneficio**: AbstracciÃ³n de detalles de BD

### 2. Strategy Pattern
**Uso**: QuestionSelectorService (diversas estrategias de selecciÃ³n)
**Beneficio**: FÃ¡cil agregar nuevas estrategias

### 3. Factory Pattern
**Uso**: CreaciÃ³n de entities con validaciones
**Beneficio**: Centraliza lÃ³gica de creaciÃ³n

### 4. Dependency Injection
**Uso**: Use Cases reciben dependencias por constructor
**Beneficio**: Testabilidad, desacoplamiento

### 5. Aggregate Pattern (DDD)
**Uso**: Interview como raÃ­z del agregado
**Beneficio**: Consistencia transaccional, encapsulaciÃ³n

### 6. Value Object Pattern (DDD)
**Uso**: Score, Emotion, SkillLevel
**Beneficio**: Inmutabilidad, validaciÃ³n en construcciÃ³n

---

## Escalabilidad y Performance

### Bottlenecks Identificados

1. **LLM API Calls**: Latencia 500ms-2s
   - **MitigaciÃ³n**: Cache de evaluaciones frecuentes (Redis, futuro)
   - **Alternativa**: Modelo local (menor calidad, mayor velocidad)

2. **ML Model Loading**: Primera carga ~2-3s
   - **MitigaciÃ³n**: Lazy loading + cache en memoria
   - **Alternativa**: Warm-up al iniciar servidor

3. **PostgreSQL Queries**: Hasta 100ms en queries complejas
   - **MitigaciÃ³n**: Ãndices optimizados, connection pooling
   - **Alternativa**: Read replicas para consultas

### Estrategias de Escalabilidad

#### Horizontal Scaling
```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Load Balancerâ”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ API Pod â”‚    â”‚ API Pod â”‚    â”‚ API Pod â”‚
   â”‚ Ready4H â”‚    â”‚ Ready4H â”‚    â”‚ Ready4H â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Shared Services    â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ PostgreSQL (Primary) â”‚
            â”‚ Redis (Cache)        â”‚
            â”‚ OpenAI API           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Caching Strategy (Futuro)
```
Cache Layers:
1. In-Memory (per-pod): Modelos ML, embeddings recientes
2. Redis: Sessions, evaluaciones frecuentes, preguntas populares
3. PostgreSQL: Datos persistentes

TTL Strategy:
- Sessions: 1h
- Evaluaciones: 24h (si misma question+answer)
- Preguntas: 1 week
- Modelos ML: No expira (warm cache)
```

---

## Seguridad

### AutenticaciÃ³n
- JWT tokens (HS256 algorithm)
- ExpiraciÃ³n: 60 minutos
- Refresh tokens: TODO

### AutorizaciÃ³n
- Usuarios solo acceden a sus entrevistas
- ValidaciÃ³n `user_id` en cada request

### ProtecciÃ³n de Datos
- API keys en variables de entorno (nunca en cÃ³digo)
- Secrets en Kubernetes Secrets / Docker Secrets
- Logs sin informaciÃ³n sensible (no API keys, no passwords)

### Rate Limiting (TODO)
```python
# Ejemplo
@app.middleware("http")
async def rate_limit(request: Request, call_next):
    # Limitar a 100 requests/min por usuario
    pass
```

---

## MigraciÃ³n y EvoluciÃ³n

### Estado Actual (v2.0)

âœ… **Completado**:
- Arquitectura DDD
- ML real (emotion, difficulty)
- Use Cases bÃ¡sicos
- Repositories (Memory, JSON)
- CI/CD Pipeline

ğŸ”„ **En Progreso**:
- API v2 endpoints
- Tests comprehensivos
- PostgreSQL repositories
- Redis caching

### Plan de MigraciÃ³n (v2.0 â†’ v2.1)

**Fase 1: API Migration** (2-3 dÃ­as)
- Crear `/api/v2/*` endpoints
- Dependency Injection Container
- DTOs
- Mantener backward compatibility (`/api/v1/*`)

**Fase 2: Testing** (3-4 dÃ­as)
- Unit tests (domain, application)
- Integration tests (use cases, repositories)
- API tests (E2E)
- Target: 80% coverage

**Fase 3: PostgreSQL** (2-3 dÃ­as)
- `PostgresInterviewRepository`
- `PostgresQuestionRepository`
- Migration scripts
- Connection pooling

**Fase 4: Cache & Monitoring** (2-3 dÃ­as)
- Redis integration
- Prometheus metrics
- OpenTelemetry tracing
- Grafana dashboards

### Backlog (v3.0)

- [ ] Frontend web (React)
- [ ] WebSocket para real-time updates
- [ ] AnÃ¡lisis de voz (speech-to-text)
- [ ] Video entrevistas con anÃ¡lisis facial
- [ ] Multi-tenancy (empresas)
- [ ] A/B testing de preguntas
- [ ] Recomendaciones de upskilling

---

## Referencias

### Libros y Recursos
- Domain-Driven Design, Eric Evans
- Clean Architecture, Robert C. Martin
- Implementing Domain-Driven Design, Vaughn Vernon
- Architecture Patterns with Python, Harry Percival & Bob Gregory

### DocumentaciÃ³n TÃ©cnica
- FastAPI: https://fastapi.tiangolo.com/
- HuggingFace Transformers: https://huggingface.co/docs/transformers
- PyTorch: https://pytorch.org/docs/
- asyncpg: https://magicstack.github.io/asyncpg/

---

**VersiÃ³n**: 2.0.0  
**Ãšltima actualizaciÃ³n**: 14 de octubre de 2025  
**Autores**: Equipo Ready4Hire  
**Licencia**: MIT
