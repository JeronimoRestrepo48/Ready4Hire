# üèõÔ∏è Arquitectura Ready4Hire - Documentaci√≥n T√©cnica

## üìã Tabla de Contenidos

1. [Visi√≥n General](#visi√≥n-general)
2. [Decisiones de Arquitectura](#decisiones-de-arquitectura)
3. [Domain Layer](#domain-layer---l√≥gica-de-negocio)
4. [Application Layer](#application-layer---casos-de-uso)
5. [Infrastructure Layer](#infrastructure-layer---implementaciones)
6. [Flujos de Datos](#flujos-de-datos)
7. [Patrones de Dise√±o](#patrones-de-dise√±o-implementados)
8. [Escalabilidad y Performance](#escalabilidad-y-performance)
9. [Seguridad](#seguridad)
10. [Migraci√≥n y Evoluci√≥n](#migraci√≥n-y-evoluci√≥n)

---

## Visi√≥n General

Ready4Hire implementa una **arquitectura limpia basada en Domain-Driven Design (DDD)** con separaci√≥n estricta de responsabilidades en 3 capas principales. Esta arquitectura reemplaza el sistema monol√≠tico anterior (1422 l√≠neas en un solo archivo) por una estructura modular, testable y mantenible.

### Principios Arquitect√≥nicos

1. **Dependency Inversion**: Las capas externas dependen de las internas, nunca al rev√©s
2. **Single Responsibility**: Cada componente tiene una √∫nica raz√≥n para cambiar
3. **Open/Closed**: Abierto para extensi√≥n, cerrado para modificaci√≥n
4. **Testability First**: Todas las capas son testeables de forma aislada
5. **Explicit is Better**: Contratos expl√≠citos (interfaces) sobre implementaciones concretas

---

## Decisiones de Arquitectura

### ADR-001: Domain-Driven Design

**Contexto**: Sistema monol√≠tico de 1422 l√≠neas dif√≠cil de mantener, testear y escalar.

**Decisi√≥n**: Adoptar DDD con separaci√≥n en 3 capas (Domain, Application, Infrastructure).

**Consecuencias**:
- ‚úÖ **Positivas**: 
  - L√≥gica de negocio aislada y testeable
  - Facilita agregar nuevas features sin romper existentes
  - Permite cambiar implementaciones (BD, ML) sin tocar dominio
- ‚ö†Ô∏è **Negativas**:
  - Mayor cantidad de archivos (50+ vs 8)
  - Curva de aprendizaje para desarrolladores nuevos
  - M√°s boilerplate inicial

**Alternativas consideradas**:
- MVC tradicional: Rechazado (mezcla l√≥gica de negocio con presentaci√≥n)
- Microservicios: Rechazado (overhead para tama√±o actual del proyecto)

---

### ADR-002: ML Real vs Stubs

**Contexto**: Sistema anterior usaba "ML fake" (stubs con l√≥gica hardcodeada).

**Decisi√≥n**: Implementar modelos ML reales (HuggingFace Transformers, PyTorch).

**Consecuencias**:
- ‚úÖ **Positivas**:
  - Detecci√≥n real de emociones con 85%+ precisi√≥n
  - Soporte multiling√ºe (ES + EN)
  - Ajuste din√°mico de dificultad basado en features reales
- ‚ö†Ô∏è **Negativas**:
  - Mayor uso de CPU/RAM (modelos ~500MB)
  - Latencia adicional en primera inferencia (~2-3s, luego <200ms)
  - Requiere gesti√≥n de cache de modelos

**Mitigaci√≥n**:
- Lazy loading de modelos (solo se cargan cuando se usan)
- Cache de modelos en memoria
- Fallback heur√≠stico si ML falla

---

### ADR-003: LLM para Evaluaci√≥n

**Contexto**: Necesidad de evaluar respuestas de forma inteligente y contextual.

**Decisi√≥n**: Usar LLMs (OpenAI GPT-4 / Anthropic Claude) con fallback heur√≠stico.

**Consecuencias**:
- ‚úÖ **Positivas**:
  - Evaluaci√≥n profunda y contextualizada
  - Feedback personalizado de alta calidad
  - Captura conceptos que heur√≠sticas no detectan
- ‚ö†Ô∏è **Negativas**:
  - Dependencia de APIs externas (costo, latencia, disponibilidad)
  - Costo variable seg√∫n uso (~$0.03-0.06 por respuesta con GPT-4)

**Mitigaci√≥n**:
- Fallback heur√≠stico autom√°tico (basado en longitud, keywords)
- Rate limiting y retry logic
- Cache de evaluaciones frecuentes (futuro)

---

## Domain Layer - L√≥gica de Negocio

### Entities (Entidades)

#### Interview (Aggregate Root)
```python
class Interview:
    """
    Ra√≠z del agregado Interview.
    Orquesta toda la l√≥gica de una entrevista.
    """
    def __init__(
        self,
        id: str,
        user_id: str,
        role: str,
        category: str,
        current_difficulty: SkillLevel,
        max_questions: int = 10
    ):
        self.id = id
        self.user_id = user_id
        self.role = role
        self.category = category
        self.status = InterviewStatus.CREATED
        self.current_difficulty = current_difficulty
        self.max_questions = max_questions
        self.current_question_index = 0
        self.questions: List[str] = []  # IDs de preguntas
        self.answers: List[Answer] = []
        # Timestamps
        self.created_at = datetime.utcnow()
        self.started_at: Optional[datetime] = None
        self.completed_at: Optional[datetime] = None
        self.paused_at: Optional[datetime] = None
    
    # M√©todos de negocio
    def start(self) -> None:
        """Iniciar entrevista con validaciones."""
        if self.status != InterviewStatus.CREATED:
            raise ValueError("Interview already started")
        self.status = InterviewStatus.ACTIVE
        self.started_at = datetime.utcnow()
    
    def add_question(self, question_id: str) -> None:
        """Agregar pregunta con validaciones."""
        if self.status not in [InterviewStatus.ACTIVE, InterviewStatus.PAUSED]:
            raise ValueError("Cannot add question to inactive interview")
        if len(self.questions) >= self.max_questions:
            raise ValueError("Max questions reached")
        self.questions.append(question_id)
    
    def add_answer(self, answer: Answer) -> None:
        """Agregar respuesta y actualizar estado."""
        if self.status != InterviewStatus.ACTIVE:
            raise ValueError("Interview not active")
        self.answers.append(answer)
        self.current_question_index += 1
    
    def get_score_average(self) -> float:
        """Calcular promedio de puntuaciones."""
        if not self.answers:
            return 0.0
        scores = [a.score.value for a in self.answers if a.score]
        return sum(scores) / len(scores) if scores else 0.0
    
    def get_accuracy(self) -> float:
        """Calcular porcentaje de respuestas correctas (score >= 6)."""
        if not self.answers:
            return 0.0
        correct = sum(1 for a in self.answers if a.score and a.score.value >= 6.0)
        return (correct / len(self.answers)) * 100
    
    def needs_difficulty_adjustment(self) -> bool:
        """Determinar si se debe ajustar dificultad."""
        if len(self.answers) < 3:
            return False
        recent_scores = [a.score.value for a in self.answers[-3:] if a.score]
        avg_recent = sum(recent_scores) / len(recent_scores) if recent_scores else 0
        # Subir si √∫ltimas 3 respuestas promedio >= 7.5
        # Bajar si √∫ltimas 3 respuestas promedio < 5.0
        return avg_recent >= 7.5 or avg_recent < 5.0
```

**Reglas de negocio en Interview:**
1. Solo se puede iniciar una entrevista CREATED
2. Solo se pueden agregar preguntas si est√° ACTIVE o PAUSED
3. M√°ximo `max_questions` preguntas por entrevista
4. Ajuste de dificultad basado en √∫ltimas 3 respuestas
5. Accuracy considera correctas las respuestas con score >= 6.0

#### Question
```python
@dataclass
class Question:
    """Entidad Question con metadata para evaluaci√≥n."""
    id: str
    role: str
    category: str  # 'technical' | 'soft_skills'
    difficulty: SkillLevel
    question_text: str
    keywords: List[str]
    expected_concepts: List[str]
    metadata: Dict[str, Any] = field(default_factory=dict)
```

#### Answer
```python
@dataclass
class Answer:
    """Entidad Answer con evaluaci√≥n completa."""
    id: str
    question_id: str
    answer_text: str
    score: Score
    emotion: Emotion
    time_taken_seconds: int
    hints_used: int = 0
    evaluation_details: Dict[str, Any] = field(default_factory=dict)
    feedback: str = ""
    created_at: datetime = field(default_factory=datetime.utcnow)
```

### Value Objects

#### Score
```python
class Score:
    """
    Value Object para puntuaciones (0-10).
    Inmutable, validado.
    """
    def __init__(self, value: float):
        if not 0 <= value <= 10:
            raise ValueError("Score must be between 0 and 10")
        self._value = round(value, 1)
    
    @property
    def value(self) -> float:
        return self._value
    
    def is_passing(self) -> bool:
        """Considera aprobado si score >= 6.0"""
        return self._value >= 6.0
    
    def quality_level(self) -> str:
        """Retorna nivel de calidad."""
        if self._value >= 9.0:
            return "excellent"
        elif self._value >= 7.0:
            return "good"
        elif self._value >= 5.0:
            return "acceptable"
        else:
            return "needs_improvement"
```

#### Emotion
```python
class Emotion(Enum):
    """Enum de emociones detectables."""
    JOY = "joy"
    SADNESS = "sadness"
    ANGER = "anger"
    FEAR = "fear"
    SURPRISE = "surprise"
    NEUTRAL = "neutral"
    
    def sentiment(self) -> str:
        """Clasifica en positivo/negativo/neutral."""
        if self in [Emotion.JOY, Emotion.SURPRISE]:
            return "positive"
        elif self in [Emotion.SADNESS, Emotion.ANGER, Emotion.FEAR]:
            return "negative"
        else:
            return "neutral"
```

#### SkillLevel
```python
class SkillLevel(Enum):
    """Niveles de habilidad con transiciones."""
    JUNIOR = "junior"
    MID = "mid"
    SENIOR = "senior"
    
    def can_increase_to(self, other: 'SkillLevel') -> bool:
        """Valida transici√≥n v√°lida."""
        transitions = {
            SkillLevel.JUNIOR: [SkillLevel.MID],
            SkillLevel.MID: [SkillLevel.SENIOR],
            SkillLevel.SENIOR: []
        }
        return other in transitions[self]
    
    def to_numeric(self) -> int:
        """Conversi√≥n a num√©rico para c√°lculos."""
        return {
            SkillLevel.JUNIOR: 0,
            SkillLevel.MID: 1,
            SkillLevel.SENIOR: 2
        }[self]
```

### Repository Interfaces (Ports)

```python
from abc import ABC, abstractmethod

class InterviewRepository(ABC):
    """Interfaz para persistencia de Interview."""
    
    @abstractmethod
    async def save(self, interview: Interview) -> None:
        """Guardar o actualizar entrevista."""
        pass
    
    @abstractmethod
    async def find_by_id(self, interview_id: str) -> Optional[Interview]:
        """Buscar por ID."""
        pass
    
    @abstractmethod
    async def find_active_by_user(self, user_id: str) -> Optional[Interview]:
        """Buscar entrevista activa del usuario."""
        pass
    
    @abstractmethod
    async def find_all_by_user(self, user_id: str) -> List[Interview]:
        """Listar todas las entrevistas de un usuario."""
        pass
```

**Beneficios del Repository Pattern:**
- Domain no conoce detalles de persistencia (SQL, NoSQL, memoria)
- F√°cil cambiar implementaci√≥n (Memory ‚Üí PostgreSQL)
- Testeabilidad con mocks
- Queries de negocio encapsuladas

---

## Application Layer - Casos de Uso

### Use Cases

#### StartInterviewUseCase
```python
class StartInterviewUseCase:
    """
    Caso de uso: Iniciar nueva entrevista.
    Orquesta validaciones, creaci√≥n de entidad y persistencia.
    """
    def __init__(
        self,
        interview_repo: InterviewRepository,
        question_repo: QuestionRepository,
        question_selector: QuestionSelectorService
    ):
        self.interview_repo = interview_repo
        self.question_repo = question_repo
        self.question_selector = question_selector
    
    async def execute(
        self,
        user_id: str,
        role: str,
        category: str,
        initial_difficulty: SkillLevel = SkillLevel.MID
    ) -> Dict[str, Any]:
        """
        Flujo:
        1. Validar que no haya entrevista activa
        2. Crear Interview entity
        3. Seleccionar primera pregunta
        4. Iniciar entrevista
        5. Persistir
        6. Retornar resultado
        """
        # 1. Validar
        existing = await self.interview_repo.find_active_by_user(user_id)
        if existing:
            raise ValueError("User already has active interview")
        
        # 2. Crear entidad
        interview = Interview(
            id=str(uuid.uuid4()),
            user_id=user_id,
            role=role,
            category=category,
            current_difficulty=initial_difficulty
        )
        
        # 3. Seleccionar primera pregunta
        first_question = await self.question_selector.select_initial_question(
            role=role,
            category=category,
            difficulty=initial_difficulty
        )
        
        # 4. Iniciar
        interview.start()
        interview.add_question(first_question.id)
        
        # 5. Persistir
        await self.interview_repo.save(interview)
        
        # 6. Retornar
        return {
            "interview_id": interview.id,
            "message": f"¬°Bienvenido! Entrevista {category} para {role}.",
            "first_question": {
                "id": first_question.id,
                "text": first_question.question_text,
                "difficulty": first_question.difficulty.value
            }
        }
```

#### ProcessAnswerUseCase
```python
class ProcessAnswerUseCase:
    """
    Caso de uso: Procesar respuesta del candidato.
    Orquesta detecci√≥n emoci√≥n, evaluaci√≥n, feedback y siguiente pregunta.
    """
    def __init__(
        self,
        interview_repo: InterviewRepository,
        question_repo: QuestionRepository,
        emotion_detector: MultilingualEmotionDetector,
        evaluation_service: EvaluationService,
        feedback_service: FeedbackService,
        question_selector: QuestionSelectorService
    ):
        self.interview_repo = interview_repo
        self.question_repo = question_repo
        self.emotion_detector = emotion_detector
        self.evaluation_service = evaluation_service
        self.feedback_service = feedback_service
        self.question_selector = question_selector
    
    async def execute(
        self,
        interview_id: str,
        answer_text: str
    ) -> Dict[str, Any]:
        """
        Flujo:
        1. Recuperar entrevista y pregunta actual
        2. Detectar emoci√≥n
        3. Evaluar respuesta con LLM
        4. Generar feedback personalizado
        5. Crear Answer entity
        6. Seleccionar siguiente pregunta (si no termin√≥)
        7. Persistir
        8. Retornar resultado
        """
        # 1. Recuperar
        interview = await self.interview_repo.find_by_id(interview_id)
        if not interview:
            raise ValueError("Interview not found")
        
        current_q_id = interview.questions[-1]
        question = await self.question_repo.find_by_id(current_q_id)
        
        # 2. Detectar emoci√≥n
        emotion_result = self.emotion_detector.detect(answer_text)
        emotion = emotion_result['emotion']
        
        # 3. Evaluar
        evaluation = await self.evaluation_service.evaluate_answer(
            question=question.question_text,
            answer=answer_text,
            expected_concepts=question.expected_concepts,
            keywords=question.keywords,
            category=question.category,
            difficulty=question.difficulty.value,
            role=question.role
        )
        
        # 4. Feedback
        feedback = await self.feedback_service.generate_feedback(
            question=question.question_text,
            answer=answer_text,
            evaluation=evaluation,
            emotion=emotion.value,
            role=interview.role,
            category=interview.category,
            performance_history=[a.to_dict() for a in interview.answers]
        )
        
        # 5. Crear Answer
        answer = Answer(
            id=str(uuid.uuid4()),
            question_id=question.id,
            answer_text=answer_text,
            score=Score(evaluation['score']),
            emotion=emotion,
            time_taken_seconds=0,  # TODO: trackear tiempo
            evaluation_details=evaluation,
            feedback=feedback
        )
        
        interview.add_answer(answer)
        
        # 6. Siguiente pregunta
        next_question = None
        if interview.current_question_index < interview.max_questions:
            next_question = await self.question_selector.select_next_question(
                interview=interview,
                previous_question_ids=interview.questions,
                last_answer_score=evaluation['score']
            )
            if next_question:
                interview.add_question(next_question.id)
        else:
            interview.complete()
        
        # 7. Persistir
        await self.interview_repo.save(interview)
        
        # 8. Retornar
        result = {
            "evaluation": evaluation,
            "emotion": {
                "detected": emotion.value,
                "confidence": emotion_result['confidence'],
                "language": emotion_result['language']
            },
            "feedback": feedback,
            "progress": {
                "current": interview.current_question_index,
                "total": interview.max_questions,
                "percentage": (interview.current_question_index / interview.max_questions) * 100
            }
        }
        
        if next_question:
            result["next_question"] = {
                "id": next_question.id,
                "text": next_question.question_text,
                "difficulty": next_question.difficulty.value
            }
        
        return result
```

### Services (Servicios de Aplicaci√≥n)

#### EvaluationService
**Responsabilidad**: Evaluar respuestas usando LLM con fallback heur√≠stico.

**Algoritmo**:
1. Construir prompt estructurado con contexto
2. Llamar LLM (OpenAI/Anthropic)
3. Parsear respuesta JSON
4. Validar estructura y rangos
5. Si falla: usar evaluaci√≥n heur√≠stica (longitud, keywords)

**Input**: Question, Answer, ExpectedConcepts, Keywords
**Output**: 
```json
{
  "score": 7.5,
  "breakdown": {
    "completeness": 2.5,
    "technical_depth": 2.0,
    "clarity": 1.5,
    "key_concepts": 1.5
  },
  "justification": "...",
  "strengths": ["...", "..."],
  "improvements": ["...", "..."],
  "concepts_covered": ["...", "..."]
}
```

#### FeedbackService
**Responsabilidad**: Generar feedback personalizado considerando emoci√≥n.

**Estrategia**:
- Tono adaptado a emoci√≥n:
  - `joy/neutral`: Positivo y motivador
  - `sadness/fear`: Emp√°tico y alentador
  - `anger`: Calmado y comprensivo
  - `surprise`: Entusiasta y gu√≠a

**Longitud**: 80-120 palabras (3-4 oraciones)

#### QuestionSelectorService
**Responsabilidad**: Seleccionar siguiente pregunta adapt√°ndose al rendimiento.

**Estrategia de selecci√≥n**:
1. **Ajuste de dificultad**:
   - Si score √∫ltima respuesta >= 7.5: Subir dificultad
   - Si score < 5.0: Bajar dificultad
   - Else: Mantener

2. **Diversidad sem√°ntica** (si embeddings disponibles):
   - Calcular distancia coseno con √∫ltimas 3 preguntas
   - Seleccionar la m√°s diversa (m√°xima distancia promedio)

3. **Fallback**:
   - Selecci√≥n aleatoria de pool v√°lido

---

## Infrastructure Layer - Implementaciones

### Persistence (Adaptadores)

#### MemoryInterviewRepository
```python
class MemoryInterviewRepository(InterviewRepository):
    """Implementaci√≥n en memoria (desarrollo, tests)."""
    def __init__(self):
        self._storage: Dict[str, Interview] = {}
        self._user_index: Dict[str, List[str]] = {}
    
    async def save(self, interview: Interview) -> None:
        self._storage[interview.id] = interview
        if interview.user_id not in self._user_index:
            self._user_index[interview.user_id] = []
        if interview.id not in self._user_index[interview.user_id]:
            self._user_index[interview.user_id].append(interview.id)
    
    async def find_by_id(self, interview_id: str) -> Optional[Interview]:
        return self._storage.get(interview_id)
    
    async def find_active_by_user(self, user_id: str) -> Optional[Interview]:
        interview_ids = self._user_index.get(user_id, [])
        for iid in interview_ids:
            interview = self._storage.get(iid)
            if interview and interview.status == InterviewStatus.ACTIVE:
                return interview
        return None
```

#### PostgresInterviewRepository (TODO)
```python
class PostgresInterviewRepository(InterviewRepository):
    """Implementaci√≥n con PostgreSQL (async)."""
    def __init__(self, pool: asyncpg.Pool):
        self.pool = pool
    
    async def save(self, interview: Interview) -> None:
        async with self.pool.acquire() as conn:
            # Serializar Interview a JSON
            data = interview.to_dict()
            await conn.execute("""
                INSERT INTO interviews (id, user_id, role, status, data, updated_at)
                VALUES ($1, $2, $3, $4, $5, NOW())
                ON CONFLICT (id) DO UPDATE SET
                    status = EXCLUDED.status,
                    data = EXCLUDED.data,
                    updated_at = NOW()
            """, interview.id, interview.user_id, interview.role, 
                interview.status.value, json.dumps(data))
```

### ML Models (Adaptadores)

#### MultilingualEmotionDetector
**Tecnolog√≠a**: HuggingFace Transformers

**Modelos**:
- Espa√±ol: `finiteautomata/bertweet-base-emotion-analysis`
- Ingl√©s: `j-hartmann/emotion-english-distilroberta-base`

**Flujo**:
1. Detectar idioma con `langid`
2. Cargar modelo apropiado (lazy loading)
3. Ejecutar inferencia
4. Mapear labels a `Emotion` enum
5. Retornar resultado con confianza

**Performance**:
- Primera inferencia: ~2-3s (descarga modelo)
- Siguientes: <200ms (modelo en cache)
- Tama√±o modelos: ~500MB total

#### NeuralDifficultyAdjuster
**Tecnolog√≠a**: PyTorch

**Arquitectura**:
```
Input Layer (12 features)
    ‚Üì
Dense(64) + ReLU
    ‚Üì
Dense(32) + ReLU
    ‚Üì
Output Layer (3) ‚Üí Softmax
    ‚Üì
[P(JUNIOR), P(MID), P(SENIOR)]
```

**Features extra√≠das**:
1. avg_score: Promedio de puntuaciones
2. consistency: Desviaci√≥n est√°ndar de scores
3. avg_time: Tiempo promedio de respuesta
4. emotion_positive_ratio: % emociones positivas
5. emotion_negative_ratio: % emociones negativas
6. correct_ratio: % respuestas correctas (score >= 6)
7. accuracy: Precisi√≥n general
8. hints_used_avg: Promedio de pistas usadas
9. current_difficulty_num: Dificultad actual (0-2)
10. questions_answered: Cantidad respondidas
11. trend: Tendencia (√∫ltimas 3 respuestas)
12. time_variance: Varianza de tiempos

**Training**: TODO (actualmente usa heur√≠stica hasta entrenar modelo)

---

## Flujos de Datos

### Flujo Completo: Responder Pregunta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. API Endpoint                                               ‚îÇ
‚îÇ    POST /answer                                               ‚îÇ
‚îÇ    Body: {user_id, answer_text}                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. ProcessAnswerUseCase.execute()                            ‚îÇ
‚îÇ    - Recuperar Interview del repositorio                      ‚îÇ
‚îÇ    - Recuperar Question actual                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº            ‚ñº            ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇEmotion ‚îÇ  ‚îÇEvaluation  ‚îÇ  ‚îÇFeedback‚îÇ  ‚îÇQuestion  ‚îÇ
‚îÇDetector‚îÇ  ‚îÇService     ‚îÇ  ‚îÇService ‚îÇ  ‚îÇSelector  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ             ‚îÇ             ‚îÇ            ‚îÇ
    ‚îÇ detect()    ‚îÇ evaluate()  ‚îÇ generate() ‚îÇ select_next()
    ‚îÇ             ‚îÇ             ‚îÇ            ‚îÇ
    ‚ñº             ‚ñº             ‚ñº            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇML Model‚îÇ  ‚îÇOpenAI/     ‚îÇ  ‚îÇOpenAI/ ‚îÇ  ‚îÇEmbeddings‚îÇ
‚îÇ(Trans- ‚îÇ  ‚îÇAnthropic   ‚îÇ  ‚îÇAnthrop ‚îÇ  ‚îÇManager   ‚îÇ
‚îÇformers)‚îÇ  ‚îÇAPI         ‚îÇ  ‚îÇic API  ‚îÇ  ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ             ‚îÇ             ‚îÇ            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Crear Answer Entity                                        ‚îÇ
‚îÇ    Answer(score, emotion, feedback, ...)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Actualizar Interview                                       ‚îÇ
‚îÇ    interview.add_answer(answer)                               ‚îÇ
‚îÇ    interview.add_question(next_question_id)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Persistir                                                  ‚îÇ
‚îÇ    interview_repo.save(interview)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Retornar Resultado                                         ‚îÇ
‚îÇ    {evaluation, emotion, feedback, next_question, progress}   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos: Detecci√≥n de Emoci√≥n

```
answer_text
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ MultilingualEmotionDet  ‚îÇ
‚îÇ .detect(text)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ langid.classify(text)   ‚îÇ
‚îÇ ‚Üí 'es' | 'en'           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇES Model‚îÇ ‚îÇEN Model‚îÇ
‚îÇbertweet‚îÇ ‚îÇdistil  ‚îÇ
‚îÇ        ‚îÇ ‚îÇroberta ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ results = [             ‚îÇ
‚îÇ   {label: 'joy',        ‚îÇ
‚îÇ    score: 0.85},        ‚îÇ
‚îÇ   {label: 'neutral',    ‚îÇ
‚îÇ    score: 0.10},        ‚îÇ
‚îÇ   ...                   ‚îÇ
‚îÇ ]                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ best = max(results)     ‚îÇ
‚îÇ emotion = map_to_enum() ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
{
  'emotion': Emotion.JOY,
  'confidence': 0.85,
  'all_emotions': [...],
  'language': 'es'
}
```

---

## Patrones de Dise√±o Implementados

### 1. Repository Pattern
**Uso**: Persistencia de Interviews y Questions
**Beneficio**: Abstracci√≥n de detalles de BD

### 2. Strategy Pattern
**Uso**: QuestionSelectorService (diversas estrategias de selecci√≥n)
**Beneficio**: F√°cil agregar nuevas estrategias

### 3. Factory Pattern
**Uso**: Creaci√≥n de entities con validaciones
**Beneficio**: Centraliza l√≥gica de creaci√≥n

### 4. Dependency Injection
**Uso**: Use Cases reciben dependencias por constructor
**Beneficio**: Testabilidad, desacoplamiento

### 5. Aggregate Pattern (DDD)
**Uso**: Interview como ra√≠z del agregado
**Beneficio**: Consistencia transaccional, encapsulaci√≥n

### 6. Value Object Pattern (DDD)
**Uso**: Score, Emotion, SkillLevel
**Beneficio**: Inmutabilidad, validaci√≥n en construcci√≥n

---

## Escalabilidad y Performance

### Bottlenecks Identificados

1. **LLM API Calls**: Latencia 500ms-2s
   - **Mitigaci√≥n**: Cache de evaluaciones frecuentes (Redis, futuro)
   - **Alternativa**: Modelo local (menor calidad, mayor velocidad)

2. **ML Model Loading**: Primera carga ~2-3s
   - **Mitigaci√≥n**: Lazy loading + cache en memoria
   - **Alternativa**: Warm-up al iniciar servidor

3. **PostgreSQL Queries**: Hasta 100ms en queries complejas
   - **Mitigaci√≥n**: √çndices optimizados, connection pooling
   - **Alternativa**: Read replicas para consultas

### Estrategias de Escalabilidad

#### Horizontal Scaling
```
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ Load Balancer‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº               ‚ñº               ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ API Pod ‚îÇ    ‚îÇ API Pod ‚îÇ    ‚îÇ API Pod ‚îÇ
   ‚îÇ Ready4H ‚îÇ    ‚îÇ Ready4H ‚îÇ    ‚îÇ Ready4H ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Shared Services    ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
            ‚îÇ PostgreSQL (Primary) ‚îÇ
            ‚îÇ Redis (Cache)        ‚îÇ
            ‚îÇ OpenAI API           ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Caching Strategy (Futuro)
```
Cache Layers:
1. In-Memory (per-pod): Modelos ML, embeddings recientes
2. Redis: Sessions, evaluaciones frecuentes, preguntas populares
3. PostgreSQL: Datos persistentes

TTL Strategy:
- Sessions: 1h
- Evaluaciones: 24h (si misma question+answer)
- Preguntas: 1 week
- Modelos ML: No expira (warm cache)
```

---

## Seguridad

### Autenticaci√≥n
- JWT tokens (HS256 algorithm)
- Expiraci√≥n: 60 minutos
- Refresh tokens: TODO

### Autorizaci√≥n
- Usuarios solo acceden a sus entrevistas
- Validaci√≥n `user_id` en cada request

### Protecci√≥n de Datos
- API keys en variables de entorno (nunca en c√≥digo)
- Secrets en Kubernetes Secrets / Docker Secrets
- Logs sin informaci√≥n sensible (no API keys, no passwords)

### Rate Limiting (TODO)
```python
# Ejemplo
@app.middleware("http")
async def rate_limit(request: Request, call_next):
    # Limitar a 100 requests/min por usuario
    pass
```

---

## Migraci√≥n y Evoluci√≥n

### Estado Actual (v2.0)

‚úÖ **Completado**:
- Arquitectura DDD
- ML real (emotion, difficulty)
- Use Cases b√°sicos
- Repositories (Memory, JSON)
- CI/CD Pipeline

üîÑ **En Progreso**:
- API v2 endpoints
- Tests comprehensivos
- PostgreSQL repositories
- Redis caching

### Plan de Migraci√≥n (v2.0 ‚Üí v2.1)

**Fase 1: API Migration** (2-3 d√≠as)
- Crear `/api/v2/*` endpoints
- Dependency Injection Container
- DTOs
- Mantener backward compatibility (`/api/v1/*`)

**Fase 2: Testing** (3-4 d√≠as)
- Unit tests (domain, application)
- Integration tests (use cases, repositories)
- API tests (E2E)
- Target: 80% coverage

**Fase 3: PostgreSQL** (2-3 d√≠as)
- `PostgresInterviewRepository`
- `PostgresQuestionRepository`
- Migration scripts
- Connection pooling

**Fase 4: Cache & Monitoring** (2-3 d√≠as)
- Redis integration
- Prometheus metrics
- OpenTelemetry tracing
- Grafana dashboards

### Backlog (v3.0)

- [ ] Frontend web (React)
- [ ] WebSocket para real-time updates
- [ ] An√°lisis de voz (speech-to-text)
- [ ] Video entrevistas con an√°lisis facial
- [ ] Multi-tenancy (empresas)
- [ ] A/B testing de preguntas
- [ ] Recomendaciones de upskilling

---

## Referencias

### Libros y Recursos
- Domain-Driven Design, Eric Evans
- Clean Architecture, Robert C. Martin
- Implementing Domain-Driven Design, Vaughn Vernon
- Architecture Patterns with Python, Harry Percival & Bob Gregory

### Documentaci√≥n T√©cnica
- FastAPI: https://fastapi.tiangolo.com/
- HuggingFace Transformers: https://huggingface.co/docs/transformers
- PyTorch: https://pytorch.org/docs/
- asyncpg: https://magicstack.github.io/asyncpg/

---

**Versi√≥n**: 2.0.0  
**√öltima actualizaci√≥n**: 14 de octubre de 2025  
**Autores**: Equipo Ready4Hire  
**Licencia**: MIT
