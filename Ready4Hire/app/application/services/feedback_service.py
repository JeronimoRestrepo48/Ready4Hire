"""
Servicio de generaciÃ³n de feedback personalizado usando Ollama.
Genera retroalimentaciÃ³n constructiva basada en el desempeÃ±o.
"""

from typing import Dict, Any, List, Optional
from datetime import datetime
import re
import logging

from app.infrastructure.llm.llm_service import OllamaLLMService
from app.infrastructure.llm.response_sanitizer import ResponseSanitizer
from app.domain.value_objects.emotion import Emotion

logger = logging.getLogger(__name__)


class FeedbackService:
    """
    Servicio para generar feedback personalizado usando Ollama local.
    Adapta el tono segÃºn la emociÃ³n detectada y el rendimiento.
    """

    def __init__(
        self, llm_service: Optional[OllamaLLMService] = None, model: str = "llama3.2:3b", temperature: float = 0.7
    ):
        """
        Inicializa el servicio de feedback.

        Args:
            llm_service: Servicio LLM Ollama (se crea uno si no se provee)
            model: Modelo Ollama a usar
            temperature: Temperatura (mÃ¡s alta = mÃ¡s creativo)
        """
        self.llm_service = llm_service or OllamaLLMService(model=model, temperature=temperature, max_tokens=256)
        self.model = model
        self.temperature = temperature
        self.sanitizer = ResponseSanitizer()

    def _get_profession_context(self, role: str, category: str) -> str:
        """Genera contexto especÃ­fico segÃºn la profesiÃ³n para feedback mÃ¡s relevante."""
        role_lower = role.lower()

        # Contextos especÃ­ficos por tipo de profesiÃ³n
        if any(tech in role_lower for tech in ["developer", "engineer", "programmer", "architect"]):
            return """**Enfoque para roles tÃ©cnicos:**
- Valora la precisiÃ³n tÃ©cnica y el uso correcto de terminologÃ­a
- Reconoce ejemplos de cÃ³digo, arquitecturas o soluciones prÃ¡cticas
- Sugiere mejoras en profundidad tÃ©cnica cuando sea necesario"""
        elif any(data in role_lower for data in ["data", "analyst", "scientist"]):
            return """**Enfoque para roles de datos:**
- Aprecia el pensamiento analÃ­tico y uso de datos
- Valora menciones de herramientas, metodologÃ­as y mÃ©tricas
- Sugiere mejoras en anÃ¡lisis o visualizaciÃ³n cuando aplique"""
        elif any(design in role_lower for design in ["designer", "ux", "ui"]):
            return """**Enfoque para roles de diseÃ±o:**
- Valora creatividad, empatÃ­a con usuarios y proceso de diseÃ±o
- Reconoce menciones de herramientas y principios de diseÃ±o
- Sugiere mejoras en UX research o iteraciÃ³n de diseÃ±o"""
        elif any(biz in role_lower for biz in ["manager", "product", "business", "analyst"]):
            return """**Enfoque para roles de negocio:**
- Aprecia pensamiento estratÃ©gico y orientaciÃ³n a resultados
- Valora ejemplos de liderazgo, toma de decisiones y mÃ©tricas
- Sugiere mejoras en gestiÃ³n de stakeholders o impacto de negocio"""
        elif any(mkt in role_lower for mkt in ["marketing", "sales", "content"]):
            return """**Enfoque para roles comerciales/marketing:**
- Valora creatividad, orientaciÃ³n a resultados y conocimiento del cliente
- Reconoce mÃ©tricas de rendimiento y casos de Ã©xito
- Sugiere mejoras en estrategia o ejecuciÃ³n de campaÃ±as"""
        else:
            return f"""**Enfoque para {role}:**
- Valora conocimiento especÃ­fico del rol y experiencia prÃ¡ctica
- Reconoce habilidades profesionales demostradas
- Sugiere mejoras relevantes para el contexto del puesto"""

    def generate_feedback(
        self,
        question: str,
        answer: str,
        evaluation: Dict[str, Any],
        emotion: Emotion,
        role: str,
        category: str,
        performance_history: Optional[List[Dict[str, Any]]] = None,
    ) -> str:
        """
        Genera feedback personalizado para el candidato.

        Args:
            question: Pregunta realizada
            answer: Respuesta del candidato
            evaluation: Resultado de la evaluaciÃ³n
            emotion: EmociÃ³n detectada (Enum)
            role: Rol/posiciÃ³n
            category: CategorÃ­a (soft_skills, technical)
            performance_history: Historial de respuestas anteriores

        Returns:
            Feedback personalizado y constructivo
        """
        try:
            prompt = self._build_feedback_prompt(
                question=question,
                answer=answer,
                evaluation=evaluation,
                emotion=emotion,
                role=role,
                category=category,
                performance_history=performance_history,
            )

            # Generar feedback con Ollama
            feedback = self.llm_service.generate(prompt=prompt, temperature=self.temperature, max_tokens=256)

            # Limpiar feedback (eliminar etiquetas, etc.)
            feedback = self._clean_feedback(feedback)
            
            # Sanitizar para que parezca de agente especializado
            feedback = self.sanitizer.sanitize_feedback(feedback, role=role, category=category)

            return feedback

        except Exception as e:
            logger.error(f"Error generando feedback con LLM: {str(e)}, usando fallback")
            # Fallback a feedback genÃ©rico
            return self._generate_fallback_feedback(evaluation.get("score", 5.0), emotion)

    def _build_feedback_prompt(
        self,
        question: str,
        answer: str,
        evaluation: Dict[str, Any],
        emotion: Emotion,
        role: str,
        category: str,
        performance_history: Optional[List[Dict[str, Any]]] = None,
    ) -> str:
        """Construye el prompt para generar feedback personalizado."""

        score = evaluation.get("score", 0)
        breakdown = evaluation.get("breakdown", {})
        strengths = evaluation.get("strengths", [])
        improvements = evaluation.get("improvements", [])

        # Contexto de rendimiento histÃ³rico
        history_context = ""
        if performance_history and len(performance_history) > 0:
            avg_score = sum(h.get("score", 0) for h in performance_history) / len(performance_history)
            history_context = f"""
**Contexto de desempeÃ±o:**
- Promedio en respuestas anteriores: {avg_score:.1f}/10
- NÃºmero de respuestas previas: {len(performance_history)}
- Tendencia: {"ğŸ“ˆ Mejorando" if score >= avg_score else "ğŸ“Š Estable"}
"""

        # Mapear emociÃ³n a nombre
        emotion_name = emotion.value if isinstance(emotion, Emotion) else str(emotion)

        # Contexto profesional especÃ­fico
        profession_context = self._get_profession_context(role, category)

        return f"""Mentor senior {role}. Feedback profesional (3-4 oraciones).

Rol: {role} | CategorÃ­a: {category} | EmociÃ³n: {emotion_name}
Score: {score}/10 | Comp: {breakdown.get('completeness', 0):.1f}/3 | Prof: {breakdown.get('technical_depth', 0):.1f}/3 | Clar: {breakdown.get('clarity', 0):.1f}/2

P: {question}
R: {answer}

Fortalezas: {', '.join(strengths[:2]) if strengths else 'Respuesta proporcionada'}
Mejoras: {', '.join(improvements[:2]) if improvements else 'ContinÃºa desarrollando'}

{profession_context}

Instrucciones:
- NO uses "como modelo de IA", "no puedo", "como asistente"
- SÃ© directo, profesional, especÃ­fico
- Tono segÃºn emociÃ³n: {emotion_name}
- 80-120 palabras mÃ¡ximo

Feedback:"""

    def _clean_feedback(self, feedback: str) -> str:
        """Limpia el feedback eliminando etiquetas y formato innecesario."""
        # Eliminar etiquetas comunes que los LLMs pueden aÃ±adir
        patterns_to_remove = [
            r"^Feedback:\s*",
            r"^Respuesta:\s*",
            r"^Resultado:\s*",
            r"\*\*Feedback:\*\*\s*",
            r"```.*```",
        ]

        for pattern in patterns_to_remove:
            feedback = re.sub(pattern, "", feedback, flags=re.IGNORECASE | re.DOTALL)

        # Limpiar espacios extra
        feedback = re.sub(r"\s+", " ", feedback).strip()

        return feedback

    def _generate_fallback_feedback(self, score: float, emotion: Emotion) -> str:
        """Genera feedback genÃ©rico cuando el LLM falla."""

        emotion_name = emotion.value if isinstance(emotion, Emotion) else str(emotion)

        # Feedback segÃºn puntuaciÃ³n
        if score >= 8:
            base_feedback = "Â¡Excelente respuesta! ğŸ¯ Demuestras un sÃ³lido conocimiento del tema. Sigue asÃ­, tu preparaciÃ³n es evidente."
        elif score >= 6:
            base_feedback = "Buena respuesta. âœ“ Cubres los puntos principales correctamente. Considera profundizar mÃ¡s en los detalles tÃ©cnicos."
        elif score >= 4:
            base_feedback = "Tu respuesta es un buen inicio. ğŸ’¡ Te recomiendo revisar los conceptos clave y practicar con mÃ¡s ejemplos."
        else:
            base_feedback = (
                "Veo que este tema puede ser un desafÃ­o. ğŸ“š No te desanimes, te sugiero estudiar mÃ¡s este tema."
            )

        # Ajustar segÃºn emociÃ³n
        if emotion in [Emotion.SADNESS, Emotion.FEAR, Emotion.ANGER]:
            emotional_addon = " Recuerda que cada entrevista es una oportunidad para aprender. Â¡Ãnimo! ğŸ’ª"
        elif emotion == Emotion.JOY:
            emotional_addon = " Â¡Tu entusiasmo es contagioso! ğŸŒŸ"
        else:
            emotional_addon = " Â¡Continuemos con la siguiente pregunta!"

        return base_feedback + emotional_addon

    def generate_final_feedback(
        self, role: str, category: str, all_answers: List[Dict[str, Any]], overall_score: float, accuracy: float, mode: str = "practice"
    ) -> str:
        """
        Genera feedback final al completar la entrevista con MEMORIA CONVERSACIONAL COMPLETA.

        Args:
            role: Rol/posiciÃ³n
            category: CategorÃ­a
            all_answers: Todas las respuestas de la entrevista (incluye contexto + tÃ©cnicas)
            overall_score: PuntuaciÃ³n promedio general
            accuracy: Porcentaje de respuestas correctas
            mode: Modo de entrevista (practice | exam)

        Returns:
            Feedback final completo con anÃ¡lisis profundo
        """
        try:
            prompt = self._build_final_feedback_prompt(
                role=role, category=category, all_answers=all_answers, overall_score=overall_score, accuracy=accuracy, mode=mode
            )

            # Generar con Ollama (mÃ¡s tokens para anÃ¡lisis completo)
            feedback = self.llm_service.generate(prompt=prompt, temperature=0.7, max_tokens=500)

            return self._clean_feedback(feedback)

        except Exception as e:
            logger.error(f"Error generando feedback final: {str(e)}, usando fallback")
            return self._generate_fallback_final_feedback(overall_score, accuracy)

    def _build_final_feedback_prompt(
        self, role: str, category: str, all_answers: List[Dict[str, Any]], overall_score: float, accuracy: float, mode: str = "practice"
    ) -> str:
        """Construye prompt para feedback final con MEMORIA CONVERSACIONAL COMPLETA."""
        
        # Separar respuestas de contexto y tÃ©cnicas
        context_answers = [a for a in all_answers if a.get("phase") == "context"]
        technical_answers = [a for a in all_answers if a.get("phase") == "technical"]
        
        return f"""Eres un mentor experto proporcionando feedback final COMPLETO, VALIOSO y ACCIONABLE de una entrevista.

**CONTEXTO DE LA ENTREVISTA:**
- Rol/ProfesiÃ³n evaluada: {role}
- Tipo de entrevista: {category}
- Modo: {mode} ({'Modo prÃ¡ctica - aprendizaje interactivo' if mode == 'practice' else 'Modo examen - evaluaciÃ³n formal'})
- PuntuaciÃ³n promedio: {overall_score:.1f}/10
- PrecisiÃ³n: {accuracy:.1f}% ({'Excelente' if accuracy >= 80 else 'Buena' if accuracy >= 60 else 'En desarrollo'})
- Total preguntas tÃ©cnicas respondidas: {len(technical_answers)}
- Total preguntas de contexto: {len(context_answers)}

**MEMORIA CONVERSACIONAL COMPLETA:**

**1. PERFIL DEL CANDIDATO (preguntas de contexto):**
{self._format_context_history(context_answers)}

**2. RENDIMIENTO TÃ‰CNICO (preguntas principales):**
{self._format_answer_history(technical_answers)}

**TU TAREA - GENERA FEEDBACK FINAL COMPLETO Y VALIOSO:**

Genera un feedback final estructurado (10-15 oraciones, 300-450 palabras) que sea:

**1. RESUMEN EJECUTIVO (2-3 oraciones) - SÃ‰ DIRECTO Y HONESTO:**
   - EvalÃºa el desempeÃ±o general de forma equilibrada y realista
   - Menciona cÃ³mo el modo {mode} impactÃ³ en el proceso de evaluaciÃ³n
   - Proporciona una visiÃ³n general clara del nivel del candidato

**2. ANÃLISIS PROFUNDO (4-5 oraciones) - SÃ‰ ESPECÃFICO Y VALIOSO:**
   - Identifica PATRONES claros en las respuestas:
     * Â¿QuÃ© fortalezas fueron CONSISTENTES a lo largo de la entrevista?
     * Â¿QuÃ© Ã¡reas de mejora aparecieron REPETIDAMENTE?
   - RELACIONA el perfil de contexto con el rendimiento tÃ©cnico:
     * Â¿CÃ³mo se reflejaron las habilidades mencionadas en las respuestas tÃ©cnicas?
     * Â¿Hay desconexiones entre lo que dijo y lo que demostrÃ³?
   - DESTACA insights especÃ­ficos:
     * Menciona ejemplos concretos de respuestas destacables o problemÃ¡ticas
     * Identifica temas o conceptos donde el candidato mostrÃ³ mayor/menor dominio

**3. RECOMENDACIONES CONCRETAS (3-4 oraciones) - SÃ‰ ACCIONABLE:**
   - Prioriza 2-3 Ã¡reas de mejora MÃS IMPORTANTES para {role}
   - Proporciona pasos ESPECÃFICOS y ACCIONABLES:
     * "Estudia [tema especÃ­fico] enfocÃ¡ndote en [aspecto concreto]"
     * "Practica [tipo de ejercicio o proyecto] para mejorar [habilidad especÃ­fica]"
   - Sugiere recursos o enfoques de estudio RELEVANTES:
     * Menciona tipos de proyectos, Ã¡reas de prÃ¡ctica, o recursos especÃ­ficos
     * Conecta con el contexto de {role} y la industria

**4. MENSAJE MOTIVACIONAL (2-3 oraciones) - SÃ‰ GENUINO Y DINÃMICO:**
   - Reconoce el esfuerzo y el aprendizaje logrado de forma especÃ­fica
   - Motiva con un mensaje positivo pero realista
   - Proporciona perspectiva sobre el progreso y prÃ³ximos pasos
   - Usa emojis estratÃ©gicamente: ğŸ† ğŸ’ª ğŸ“ˆ ğŸ¯ â­ ğŸš€

**ESTILO Y TONO:**
- Profesional pero cercano y empÃ¡tico
- EspecÃ­fico y concreto - evita generalidades
- Valioso - el candidato debe sentir que aprendiÃ³ algo Ãºtil
- DinÃ¡mico - mantÃ©n el engagement con estructura clara y lenguaje vivo
- Adaptado al contexto de {role} y la industria

**ESTRUCTURA SUGERIDA:**
"[Resumen ejecutivo con evaluaciÃ³n general]. [AnÃ¡lisis profundo con patrones identificados y relaciÃ³n contexto-rendimiento]. [Recomendaciones concretas priorizadas y accionables]. [Mensaje motivacional genuino y orientado al futuro]."

**IMPORTANTE:**
- NO uses frases genÃ©ricas como "sigue practicando" o "estudia mÃ¡s"
- NO repitas informaciÃ³n que ya estÃ¡ en las respuestas individuales
- SÃ‰ ESPECÃFICO - menciona conceptos, temas o habilidades concretas
- PROPORCIONA VALOR - el candidato debe salir con insights claros y acciones concretas
- MANTÃ‰N EL FOCO - prioriza lo mÃ¡s importante, no intentes cubrir todo

Responde SOLO el feedback en espaÃ±ol (sin JSON, sin etiquetas), listo para mostrar directamente al candidato."""

    def _format_answer_history(self, answers: List[Dict[str, Any]]) -> str:
        """Formatea historial de respuestas tÃ©cnicas."""
        lines = []
        for i, answer in enumerate(answers, 1):
            question = answer.get("question", "N/A")
            answer_text = answer.get("answer", "N/A")
            score = answer.get("score", 0)
            is_correct = answer.get("is_correct", False)
            evaluation = answer.get("evaluation_details", {})
            
            # Truncar textos largos
            question_short = question[:100] + "..." if len(question) > 100 else question
            answer_short = answer_text[:80] + "..." if len(answer_text) > 80 else answer_text
            
            status = "âœ… Correcta" if is_correct else "âŒ Incorrecta"
            lines.append(
                f"Pregunta {i}: {question_short}\n"
                f"  Respuesta: {answer_short}\n"
                f"  Score: {score:.1f}/10 | {status}"
            )
        return "\n\n".join(lines[:10])  # MÃ¡ximo 10 para no saturar el prompt
    
    def _format_context_history(self, answers: List[Dict[str, Any]]) -> str:
        """Formatea historial de respuestas de contexto."""
        if not answers:
            return "No hay preguntas de contexto registradas."
        
        lines = []
        for i, answer in enumerate(answers, 1):
            question = answer.get("question", "N/A")
            answer_text = answer.get("answer", "N/A")
            
            # Truncar textos largos
            question_short = question[:100] + "..." if len(question) > 100 else question
            answer_short = answer_text[:120] + "..." if len(answer_text) > 120 else answer_text
            
            lines.append(
                f"Pregunta Contexto {i}: {question_short}\n"
                f"  Respuesta: {answer_short}"
            )
        return "\n\n".join(lines)

    def _generate_fallback_final_feedback(self, overall_score: float, accuracy: float) -> str:
        """Genera feedback final genÃ©rico."""

        if overall_score >= 8:
            performance_msg = "Â¡Excelente desempeÃ±o! ğŸ† Has demostrado un sÃ³lido dominio de los temas."
        elif overall_score >= 6:
            performance_msg = "Buen desempeÃ±o general. âœ“ Tienes una base sÃ³lida que puedes seguir desarrollando."
        elif overall_score >= 4:
            performance_msg = "DesempeÃ±o moderado. ğŸ“ˆ Hay Ã¡reas claras donde puedes mejorar con prÃ¡ctica."
        else:
            performance_msg = (
                "Hay mucho espacio para crecer. ğŸ“š No te desanimes, esto es una oportunidad de aprendizaje."
            )

        accuracy_msg = f"Tu precisiÃ³n fue del {accuracy:.1f}%."

        recommendation = "Te recomiendo: revisar los conceptos donde tuviste mÃ¡s dificultad, practicar con mÃ¡s ejemplos reales, y volver a intentarlo en unos dÃ­as. Â¡Cada intento te acerca mÃ¡s al Ã©xito! ğŸ’ª"

        return f"{performance_msg} {accuracy_msg} {recommendation}"
