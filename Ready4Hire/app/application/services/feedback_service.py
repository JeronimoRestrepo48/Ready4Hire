"""
Servicio de generaciÃ³n de feedback personalizado usando Ollama.
Genera retroalimentaciÃ³n constructiva basada en el desempeÃ±o.
"""
from typing import Dict, Any, List, Optional
from datetime import datetime
import re
import logging

from app.infrastructure.llm.llm_service import OllamaLLMService
from app.domain.value_objects.emotion import Emotion

logger = logging.getLogger(__name__)


class FeedbackService:
    """
    Servicio para generar feedback personalizado usando Ollama local.
    Adapta el tono segÃºn la emociÃ³n detectada y el rendimiento.
    """
    
    def __init__(
        self,
        llm_service: Optional[OllamaLLMService] = None,
        model: str = "llama3.2:3b",
        temperature: float = 0.7
    ):
        """
        Inicializa el servicio de feedback.
        
        Args:
            llm_service: Servicio LLM Ollama (se crea uno si no se provee)
            model: Modelo Ollama a usar
            temperature: Temperatura (mÃ¡s alta = mÃ¡s creativo)
        """
        self.llm_service = llm_service or OllamaLLMService(
            model=model,
            temperature=temperature,
            max_tokens=256
        )
        self.model = model
        self.temperature = temperature
    
    def generate_feedback(
        self,
        question: str,
        answer: str,
        evaluation: Dict[str, Any],
        emotion: Emotion,
        role: str,
        category: str,
        performance_history: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """
        Genera feedback personalizado para el candidato.
        
        Args:
            question: Pregunta realizada
            answer: Respuesta del candidato
            evaluation: Resultado de la evaluaciÃ³n
            emotion: EmociÃ³n detectada (Enum)
            role: Rol/posiciÃ³n
            category: CategorÃ­a (soft_skills, technical)
            performance_history: Historial de respuestas anteriores
        
        Returns:
            Feedback personalizado y constructivo
        """
        try:
            prompt = self._build_feedback_prompt(
                question=question,
                answer=answer,
                evaluation=evaluation,
                emotion=emotion,
                role=role,
                category=category,
                performance_history=performance_history
            )
            
            # Generar feedback con Ollama
            feedback = self.llm_service.generate(
                prompt=prompt,
                temperature=self.temperature,
                max_tokens=256
            )
            
            # Limpiar feedback (eliminar etiquetas, etc.)
            feedback = self._clean_feedback(feedback)
            
            return feedback
            
        except Exception as e:
            logger.error(f"Error generando feedback con LLM: {str(e)}, usando fallback")
            # Fallback a feedback genÃ©rico
            return self._generate_fallback_feedback(
                evaluation.get("score", 5.0),
                emotion
            )
    
    def _build_feedback_prompt(
        self,
        question: str,
        answer: str,
        evaluation: Dict[str, Any],
        emotion: Emotion,
        role: str,
        category: str,
        performance_history: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """Construye el prompt para generar feedback personalizado."""
        
        score = evaluation.get("score", 0)
        breakdown = evaluation.get("breakdown", {})
        strengths = evaluation.get("strengths", [])
        improvements = evaluation.get("improvements", [])
        
        # Contexto de rendimiento histÃ³rico
        history_context = ""
        if performance_history and len(performance_history) > 0:
            avg_score = sum(h.get("score", 0) for h in performance_history) / len(performance_history)
            history_context = f"""
**Contexto de desempeÃ±o:**
- Promedio en respuestas anteriores: {avg_score:.1f}/10
- NÃºmero de respuestas previas: {len(performance_history)}
- Tendencia: {"ğŸ“ˆ Mejorando" if score >= avg_score else "ğŸ“Š Estable"}
"""
        
        # Mapear emociÃ³n a nombre
        emotion_name = emotion.value if isinstance(emotion, Emotion) else str(emotion)
        
        return f"""Eres un mentor experto y empÃ¡tico que proporciona feedback constructivo a candidatos.

**Contexto:**
- Rol: {role}
- CategorÃ­a: {category}
- EmociÃ³n detectada: {emotion_name}

**Pregunta:**
{question}

**Respuesta del candidato:**
{answer}

**EvaluaciÃ³n:**
- PuntuaciÃ³n: {score}/10
- Completitud: {breakdown.get('completeness', 0):.1f}/3
- Profundidad: {breakdown.get('technical_depth', 0):.1f}/3
- Claridad: {breakdown.get('clarity', 0):.1f}/2
- Conceptos clave: {breakdown.get('key_concepts', 0):.1f}/2

**Fortalezas:**
{chr(10).join(f'âœ“ {s}' for s in strengths) if strengths else 'âœ“ Respuesta proporcionada'}

**Mejoras:**
{chr(10).join(f'â†’ {i}' for i in improvements) if improvements else 'â†’ Ninguna identificada'}

{history_context}

**Genera feedback que:**
1. Sea empÃ¡tico (ajusta tono segÃºn emociÃ³n: {emotion_name})
2. Destaque fortalezas especÃ­ficas
3. DÃ© mejoras concretas y accionables
4. Motive al candidato
5. Sea breve: 3-4 oraciones (80-120 palabras)

**Tono segÃºn emociÃ³n:**
- joy/neutral: Positivo y motivador ğŸ‰
- sadness/fear: EmpÃ¡tico y alentador ğŸ’ª
- anger: Calmado y comprensivo ğŸ¤
- surprise: Entusiasta y guÃ­a â­

Responde SOLO el feedback en espaÃ±ol, sin etiquetas ni formato adicional."""
    
    def _clean_feedback(self, feedback: str) -> str:
        """Limpia el feedback eliminando etiquetas y formato innecesario."""
        # Eliminar etiquetas comunes que los LLMs pueden aÃ±adir
        patterns_to_remove = [
            r"^Feedback:\s*",
            r"^Respuesta:\s*",
            r"^Resultado:\s*",
            r"\*\*Feedback:\*\*\s*",
            r"```.*```",
        ]
        
        for pattern in patterns_to_remove:
            feedback = re.sub(pattern, "", feedback, flags=re.IGNORECASE | re.DOTALL)
        
        # Limpiar espacios extra
        feedback = re.sub(r'\s+', ' ', feedback).strip()
        
        return feedback
    
    def _generate_fallback_feedback(
        self,
        score: float,
        emotion: Emotion
    ) -> str:
        """Genera feedback genÃ©rico cuando el LLM falla."""
        
        emotion_name = emotion.value if isinstance(emotion, Emotion) else str(emotion)
        
        # Feedback segÃºn puntuaciÃ³n
        if score >= 8:
            base_feedback = "Â¡Excelente respuesta! ğŸ¯ Demuestras un sÃ³lido conocimiento del tema. Sigue asÃ­, tu preparaciÃ³n es evidente."
        elif score >= 6:
            base_feedback = "Buena respuesta. âœ“ Cubres los puntos principales correctamente. Considera profundizar mÃ¡s en los detalles tÃ©cnicos."
        elif score >= 4:
            base_feedback = "Tu respuesta es un buen inicio. ğŸ’¡ Te recomiendo revisar los conceptos clave y practicar con mÃ¡s ejemplos."
        else:
            base_feedback = "Veo que este tema puede ser un desafÃ­o. ğŸ“š No te desanimes, te sugiero estudiar mÃ¡s este tema."
        
        # Ajustar segÃºn emociÃ³n
        if emotion in [Emotion.SADNESS, Emotion.FEAR, Emotion.ANGER]:
            emotional_addon = " Recuerda que cada entrevista es una oportunidad para aprender. Â¡Ãnimo! ğŸ’ª"
        elif emotion == Emotion.JOY:
            emotional_addon = " Â¡Tu entusiasmo es contagioso! ğŸŒŸ"
        else:
            emotional_addon = " Â¡Continuemos con la siguiente pregunta!"
        
        return base_feedback + emotional_addon
    
    def generate_final_feedback(
        self,
        role: str,
        category: str,
        all_answers: List[Dict[str, Any]],
        overall_score: float,
        accuracy: float
    ) -> str:
        """
        Genera feedback final al completar la entrevista.
        
        Args:
            role: Rol/posiciÃ³n
            category: CategorÃ­a
            all_answers: Todas las respuestas de la entrevista
            overall_score: PuntuaciÃ³n promedio general
            accuracy: Porcentaje de respuestas correctas
        
        Returns:
            Feedback final completo
        """
        try:
            prompt = self._build_final_feedback_prompt(
                role=role,
                category=category,
                all_answers=all_answers,
                overall_score=overall_score,
                accuracy=accuracy
            )
            
            # Generar con Ollama
            feedback = self.llm_service.generate(
                prompt=prompt,
                temperature=0.7,
                max_tokens=384
            )
            
            return self._clean_feedback(feedback)
            
        except Exception as e:
            logger.error(f"Error generando feedback final: {str(e)}, usando fallback")
            return self._generate_fallback_final_feedback(overall_score, accuracy)
    
    def _build_final_feedback_prompt(
        self,
        role: str,
        category: str,
        all_answers: List[Dict[str, Any]],
        overall_score: float,
        accuracy: float
    ) -> str:
        """Construye prompt para feedback final."""
        return f"""Eres un mentor experto proporcionando feedback final de entrevista.

**Contexto:**
- Rol: {role}
- CategorÃ­a: {category}
- PuntuaciÃ³n promedio: {overall_score:.1f}/10
- PrecisiÃ³n: {accuracy:.1f}%
- Total de preguntas: {len(all_answers)}

**Rendimiento por pregunta:**
{self._format_answer_history(all_answers)}

**Genera feedback final que:**
1. Resume desempeÃ±o general (honesto y equilibrado)
2. Identifica patrones (fortalezas y mejoras consistentes)
3. Da recomendaciones concretas (prÃ³ximos pasos)
4. Motiva al candidato (mensaje positivo y realista)

**Longitud:** 5-7 oraciones (150-200 palabras)

Responde SOLO el feedback en espaÃ±ol, sin etiquetas."""
    
    def _format_answer_history(self, answers: List[Dict[str, Any]]) -> str:
        """Formatea historial de respuestas."""
        lines = []
        for i, answer in enumerate(answers, 1):
            score = answer.get("score", 0)
            emotion = answer.get("emotion", "neutral")
            lines.append(f"{i}. Score: {score:.1f}/10, EmociÃ³n: {emotion}")
        return "\n".join(lines[:10])  # MÃ¡ximo 10 para no saturar el prompt
    
    def _generate_fallback_final_feedback(
        self,
        overall_score: float,
        accuracy: float
    ) -> str:
        """Genera feedback final genÃ©rico."""
        
        if overall_score >= 8:
            performance_msg = "Â¡Excelente desempeÃ±o! ğŸ† Has demostrado un sÃ³lido dominio de los temas."
        elif overall_score >= 6:
            performance_msg = "Buen desempeÃ±o general. âœ“ Tienes una base sÃ³lida que puedes seguir desarrollando."
        elif overall_score >= 4:
            performance_msg = "DesempeÃ±o moderado. ğŸ“ˆ Hay Ã¡reas claras donde puedes mejorar con prÃ¡ctica."
        else:
            performance_msg = "Hay mucho espacio para crecer. ğŸ“š No te desanimes, esto es una oportunidad de aprendizaje."
        
        accuracy_msg = f"Tu precisiÃ³n fue del {accuracy:.1f}%."
        
        recommendation = "Te recomiendo: revisar los conceptos donde tuviste mÃ¡s dificultad, practicar con mÃ¡s ejemplos reales, y volver a intentarlo en unos dÃ­as. Â¡Cada intento te acerca mÃ¡s al Ã©xito! ğŸ’ª"
        
        return f"{performance_msg} {accuracy_msg} {recommendation}"
