# Documentaci√≥n T√©cnica: Motor NLP, Embeddings, Clustering, Feedback Emocional y Aprendizaje Autom√°tico

## 1. Arquitectura General y Fundamentos Matem√°ticos

El sistema Ready4Hire utiliza una arquitectura h√≠brida de NLP y ML para personalizar, evaluar y mejorar la experiencia de entrevistas. Los componentes principales son:
- **Embeddings sem√°nticos** (SentenceTransformers, modelo `all-MiniLM-L6-v2`)
- **Clustering y selecci√≥n de preguntas** (por similitud y temas)
- **Feedback emocional y adaptativo** (an√°lisis de emociones, motivaci√≥n personalizada)
- **Ajuste din√°mico de dificultad** (ML y reglas adaptativas)
- **Aprendizaje activo y generaci√≥n autom√°tica de preguntas** (LLM, feedback loop)
- **Anal√≠tica avanzada y m√©tricas** (desempe√±o, tiempo, errores, progreso)

### 1.1 Embeddings de Texto
Cada texto (pregunta, respuesta, contexto) se convierte en un vector $\vec{x} \in \mathbb{R}^d$:

- $\text{embedding}(\text{texto}) = \vec{x}$
- Se utiliza SentenceTransformers para obtener estos vectores.

**Similitud sem√°ntica:**
$$
\text{sim}(\vec{a}, \vec{b}) = \frac{\vec{a} \cdot \vec{b}}{\|\vec{a}\| \|\vec{b}\|}
$$
Un valor cercano a 1 indica alta similitud sem√°ntica.

---

## 2. Selecci√≥n y Clustering de Preguntas

### 2.1 Perfilado del Usuario
- Tras el contexto inicial (rol, nivel, a√±os, conocimientos, herramientas), se genera un embedding de perfil.
- Se calcula la similitud de coseno entre el embedding del perfil y todos los embeddings de preguntas t√©cnicas y blandas.

### 2.2 Clustering Tem√°tico
- Las preguntas est√°n etiquetadas por tema (`topic`).
- Se agrupan por similitud y temas dominados/d√©biles usando conteo de aciertos/errores y clustering simple.
- Se seleccionan las 10 preguntas m√°s relevantes y balanceadas (t√©cnicas y blandas) para cada usuario.
- El sistema alterna preguntas t√©cnicas y blandas seg√∫n preferencia y contexto.

---

## 3. Evaluaci√≥n de Respuestas y Feedback Adaptativo

### 3.1 Proceso de Evaluaci√≥n
1. **Embeddings:** Cada respuesta del usuario se embebe y se compara con la respuesta esperada (y con buenas respuestas previas).
2. **Similitud sem√°ntica:** Si la similitud de coseno es > 0.75 (t√©cnico) o > 0.65 (soft), se considera correcta.
3. **Cobertura de conceptos:** Se extraen palabras clave de la respuesta esperada y se mide la cobertura en la respuesta del usuario (>60% = correcta).
4. **Intentos y pistas:** Cada intento adicional y uso de pista resta puntos.
5. **Feedback emocional:** Se analiza la emoci√≥n predominante en la respuesta (alegr√≠a, tristeza, frustraci√≥n, etc.) usando un modelo transformers (`j-hartmann/emotion-english-distilroberta-base`).
6. **Feedback adaptativo:** El feedback y la motivaci√≥n se ajustan din√°micamente seg√∫n la emoci√≥n detectada, patrones de error y progreso.
7. **Sugerencias de recursos:** Si el usuario falla varias veces en un tema, se recomiendan recursos externos personalizados.

### 3.2 Ejemplo de Evaluaci√≥n
- Respuesta: "Es para crear contenedores."
- Respuesta esperada: "Permite crear, desplegar y gestionar contenedores de aplicaciones."
- Similitud coseno: 0.81 ‚Üí Correcta.
- Cobertura de conceptos: 2/3 ‚Üí Correcta.
- Feedback: "¬°Respuesta correcta! üöÄ Suma un logro m√°s a tu carrera. Puntaje: 8 (intentos: 2, penalizaci√≥n por pistas: 2)"

---

## 4. Ajuste Din√°mico de Dificultad

- El sistema ajusta la dificultad de las preguntas seg√∫n la racha de aciertos/errores del usuario.
- Si responde varias preguntas seguidas correctamente, sube la dificultad (m√°s avanzadas, menos pistas).
- Si falla repetidamente, baja la dificultad y ofrece m√°s ayuda.
- El ajuste se realiza tanto por reglas como por ML (modulo `ml_dynamic_difficulty.py`).

---

## 5. Feedback Emocional y Motivacional

- Se detectan emociones negativas repetidas y se sugiere pausa o mensajes motivacionales.
- El feedback se adapta a la emoci√≥n detectada: si hay frustraci√≥n, se motiva; si hay alegr√≠a, se refuerza el logro.
- El sistema aprende nuevas frases motivacionales y emojis usando LLMs y feedback de usuarios.

---

## 6. Aprendizaje Activo y Generaci√≥n Autom√°tica de Preguntas

- Las buenas respuestas del usuario se almacenan y refrescan los embeddings para mejorar la selecci√≥n y feedback futuro.
- El sistema utiliza LLMs para crear nuevas preguntas t√©cnicas relevantes tras cada buena respuesta.
- Las nuevas preguntas se integran autom√°ticamente al dataset y a los embeddings, permitiendo que el banco de preguntas crezca y se adapte.

---

## 7. M√©tricas, Anal√≠tica y Panel de Administraci√≥n

- Se calculan aciertos, errores y porcentajes de √©xito por tipo de pregunta y por tema (clustering).
- Se identifican habilidades destacadas y a mejorar seg√∫n las respuestas y el clustering de errores.
- Se mide el tiempo de respuesta promedio y se reconoce la agilidad o se sugieren t√©cnicas de estudio si es necesario.
- El resumen final es generado por LLM, incluye estad√≠sticas, fortalezas, puntos de mejora, advertencias, clustering de temas, recursos recomendados y reconocimiento por agilidad.
- El panel admin permite analizar desempe√±o, errores frecuentes, progreso y exportar resultados.

---

## 8. Integraci√≥n de Audio: STT y TTS

- El frontend permite responder por texto o voz (STT) y escuchar las respuestas del agente (TTS).
- El backend expone endpoints `/stt` y `/tts` para integraci√≥n de audio.
- El temporizador se gestiona en frontend y backend para medir el tiempo total en modo examen.

---

## 9. Seguridad y Privacidad

- Todos los datos y m√©tricas se almacenan de forma segura y an√≥nima.
- El sistema cumple con buenas pr√°cticas de seguridad, validaci√≥n y protecci√≥n de datos.

---

## 10. Extensibilidad y Futuro

- El sistema es modular y permite agregar nuevos modelos, algoritmos ML, visualizaciones y recursos f√°cilmente.
- El feedback y la selecci√≥n de preguntas se pueden mejorar con modelos m√°s avanzados o datos adicionales.

---

**√öltima actualizaci√≥n: agosto 2025**
